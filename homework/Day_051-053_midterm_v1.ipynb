{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>376492</td>\n",
       "      <td>1041</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160127.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160215.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>11197.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160114.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2881376</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160321.0</td>\n",
       "      <td>20160329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0   1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1   1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2   1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3   1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4   2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5   2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6     73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7    163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8   3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9     94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "10   253750         8390        NaN           NaN       0.0            NaN   \n",
       "11   253750         8390     7531.0          20:5       0.0     20160327.0   \n",
       "12   376492         1041    13490.0          30:5       2.0     20160127.0   \n",
       "13  1964720         7884        NaN           NaN      10.0            NaN   \n",
       "14  1964720         7884     6704.0          20:1      10.0     20160215.0   \n",
       "15  1113008         1041        NaN           NaN       2.0            NaN   \n",
       "16  1113008         1041    11197.0          30:5       2.0     20160114.0   \n",
       "17  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "18  2881376         8390     7531.0          20:5       0.0     20160321.0   \n",
       "19  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "\n",
       "          Date  \n",
       "0   20160217.0  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10  20160327.0  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13  20160115.0  \n",
       "14         NaN  \n",
       "15  20160114.0  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18  20160329.0  \n",
       "19         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfoff = pd.read_csv('ml100marathon-02-01/train_offline.csv')\n",
    "dftest = pd.read_csv('ml100marathon-02-01/test_offline.csv')\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=True)\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "dfoff.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    710665\n",
       "-1    413773\n",
       " 1     36304\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "dfoff[\"label\"] = dfoff.apply(label, axis=1)\n",
    "dfoff[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - weekday acquired coupon\n",
    "def getWeekday(row):\n",
    "    if (np.isnan(row)) or (row==-1):\n",
    "        return row\n",
    "    else:\n",
    "        return pd.to_datetime(row, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7\n",
    "\n",
    "dfoff['weekday'] = dfoff['Date_received'].apply(getWeekday)\n",
    "dftest['weekday'] = dftest['Date_received'].apply(getWeekday)\n",
    "\n",
    "# weekday_type (weekend = 1)\n",
    "dfoff['weekday_type'] = dfoff['weekday'].apply(lambda x : 1 if x >= 6 else 0 ) # apply to trainset\n",
    "dftest['weekday_type'] = dftest['weekday'].apply(lambda x : 1 if x >= 6 else 0 ) # apply to testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(dfoff['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dfoff[weekdaycols] = tmpdf\n",
    "\n",
    "tmpdf = pd.get_dummies(dftest['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dftest[weekdaycols] = tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - coupon discount and distance\n",
    "def getDiscountType(row):\n",
    "    if row == 'null':\n",
    "        return 'null'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if row == 'null':\n",
    "        return 1.0\n",
    "    elif ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "\n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processData(df):\n",
    "    \n",
    "    # convert discunt_rate\n",
    "    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    \n",
    "    # convert distance\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    df['distance_class'] = df['Distance'].apply(lambda x : 1 if x <= 3 else 0 )\n",
    "    return df\n",
    "\n",
    "dfoff = processData(dfoff)\n",
    "dftest = processData(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total coupon_counts\n",
    "\n",
    "# if there is a coupon id, count one\n",
    "def coupon_counts(row):\n",
    "    if (np.isnan(row)):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "dfoff['coupon_counts'] = dfoff['Coupon_id'].apply(coupon_counts)\n",
    "dftest['coupon_counts'] = dftest['Coupon_id'].apply(coupon_counts)\n",
    "\n",
    "# caculate each customer's total coupon received\n",
    "cc = dfoff[['User_id','coupon_counts']].groupby('User_id',as_index=False).sum()\n",
    "cc.columns = ['User_id', 'total_coupon_received']\n",
    "dfoff = dfoff.merge(cc, on = 'User_id')\n",
    "# print(raw_train.head())\n",
    "\n",
    "cc = dftest[['User_id','coupon_counts']].groupby('User_id',as_index=False).sum()\n",
    "cc.columns = ['User_id', 'total_coupon_received']\n",
    "dftest = dftest.merge(cc, on = 'User_id')\n",
    "# print(raw_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 667753, #positive: 32472\n",
      "Valid size: 79216, #positive: 3832\n"
     ]
    }
   ],
   "source": [
    "## Naive model\n",
    "def split_train_valid(row, date_cut=\"20160416\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "    \n",
    "df = dfoff[dfoff['label'] != -1].copy()\n",
    "df[\"is_train\"] = df[\"Date_received\"].apply(split_train_valid)\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['distance_class', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'total_coupon_received', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "original_feature = ['distance_class',\n",
    "                    'discount_type',\n",
    "                    'discount_man', \n",
    "                    'discount_jian',\n",
    "                    'Distance', \n",
    "                    'total_coupon_received', \n",
    "                    'weekday_type'] + weekdaycols\n",
    "print(len(original_feature),original_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['distance_class', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'total_coupon_received', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "predictors = original_feature\n",
    "print(predictors)\n",
    "\n",
    "def check_model(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__alpha': [ 0.001, 0.01, 0.1],\n",
    "        'en__l1_ratio': [ 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "model = check_model(train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = model.predict_proba(valid[predictors])\n",
    "valid1 = valid.copy()\n",
    "valid1['pred_prob'] = y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.789, Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 22)\n",
      "(306313, 15)\n"
     ]
    }
   ],
   "source": [
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()\n",
    "\n",
    "y_test_pred = model.predict_proba(testset[predictors])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.119519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.102057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.091697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.086408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.075930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.119519\n",
       "1  1000020_8192_20160513  0.102057\n",
       "2  1000065_1455_20160527  0.091697\n",
       "3  1000085_8067_20160513  0.086408\n",
       "4  1000086_2418_20160613  0.075930"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "# out.to_csv(\"baseline_example.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.to_csv('baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized - Midterm Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "## method 1 -> try to train all the data in replace of the validation part\n",
    "\n",
    "model_01 = check_model(df, predictors)\n",
    "\n",
    "y_pred_01 = model_01.predict_proba(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.119810\n",
      "1  1000020_8192_20160513  0.098839\n",
      "2  1000065_1455_20160527  0.089662\n",
      "3  1000085_8067_20160513  0.083645\n",
      "4  1000086_2418_20160613  0.074731\n"
     ]
    }
   ],
   "source": [
    "output_01 = output.copy()\n",
    "output_01['pred_prob'] = y_pred_01[:, 1]\n",
    "out_01 = output_01.groupby(\"uid\", as_index=False).sum()\n",
    "out_01 = out_01[[\"uid\", \"pred_prob\"]]\n",
    "out_01.columns = [\"uid\", \"label\"]\n",
    "print(out_01.head())\n",
    "# out_01.to_csv('all_data_training.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000293A38411E0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\k...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000293A38411E0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\k...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    494         if self.poller is not None:\n    495             self.poller.start()\n    496         self.kernel.start()\n    497         self.io_loop = ioloop.IOLoop.current()\n    498         try:\n--> 499             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    500         except KeyboardInterrupt:\n    501             pass\n    502 \n    503 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...0293D4E6B840>))>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...0293D4E6B840>))>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x00000293D4E6B840>),)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x00000293D4E6B840>))\n    753         \"\"\"Runs a callback with error handling.\n    754 \n    755         For use in subclasses.\n    756         \"\"\"\n    757         try:\n--> 758             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x00000293D4E6B840>)\n    759             if ret is not None:\n    760                 from tornado import gen\n    761                 # Functions that return Futures typically swallow all\n    762                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 16, 15, 53, 7, 174938, tzinfo=tzutc()), 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'session': '69c95fcc03084f908798f6f45cf8d885', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'69c95fcc03084f908798f6f45cf8d885']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 16, 15, 53, 7, 174938, tzinfo=tzutc()), 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'session': '69c95fcc03084f908798f6f45cf8d885', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'69c95fcc03084f908798f6f45cf8d885'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 16, 15, 53, 7, 174938, tzinfo=tzutc()), 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'session': '69c95fcc03084f908798f6f45cf8d885', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.FunctionDef object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-20-75318c692910>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 293c1b359e8, executio...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000293C1B1C810, file \"<ipython-input-20-75318c692910>\", line 37>\n        result = <ExecutionResult object at 293c1b359e8, executio...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000293C1B1C810, file \"<ipython-input-20-75318c692910>\", line 37>, result=<ExecutionResult object at 293c1b359e8, executio...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000293C1B1C810, file \"<ipython-input-20-75318c692910>\", line 37>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import os\\nimport numpy as np\\nimport pandas as pd...ve\\nfrom sklearn.preprocessing import MinMaxScaler', \"dfoff = pd.read_csv('ml100marathon-02-01/train_o...t(dfoff.shape)\\nprint(dftest.shape)\\ndfoff.head(20)\", '## Creat target label \\n\"\"\"\\nAccording to the defi...pply(label, axis=1)\\ndfoff[\"label\"].value_counts()', '# Generate features - weekday acquired coupon\\nde...ambda x : 1 if x >= 6 else 0 ) # apply to testset', \"weekdaycols = ['weekday_' + str(i) for i in rang...columns = weekdaycols\\ndftest[weekdaycols] = tmpdf\", '# Generate features - coupon discount and distan...= processData(dfoff)\\ndftest = processData(dftest)', \"# total coupon_counts\\n\\n# if there is a coupon id...erge(cc, on = 'User_id')\\n# print(raw_test.head())\", '## Naive model\\ndef split_train_valid(row, date_c...ve: {}\".format(len(valid), valid[\"label\"].sum()))', \"original_feature = ['distance_class',\\n          ...ols\\nprint(len(original_feature),original_feature)\", \"predictors = original_feature\\nprint(predictors)\\n...       data['label'])\\n    \\n    return grid_search\", 'model = check_model(train, predictors)', \"y_valid_pred = model.predict_proba(valid[predict...d.copy()\\nvalid1['pred_prob'] = y_valid_pred[:, 1]\", 'from sklearn.metrics import roc_auc_score, accur...{:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))', \"targetset = dftest.copy()\\nprint(targetset.shape)...red_prob'] = y_test_pred[:, 1]\\nprint(test1.shape)\", 'output = pd.concat((targetset[[\"User_id\", \"Coupo...is=1)\\noutput.reset_index(drop=True, inplace=True)', '### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN...el\"], index=False) # submission format\\nout.head()', \"# out.to_csv('baseline.csv',index=False)\", '## method 1 -> try to train all the data in repl..._01 = model_01.predict_proba(testset[predictors])', \"output_01 = output.copy()\\noutput_01['pred_prob']...ut_01.to_csv('all_data_training.csv',index=False)\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {2:     User_id  Merchant_id  Coupon_id Discount_rat...7         NaN  \n18  20160329.0  \n19         NaN  , 3:  0    710665\n-1    413773\n 1     36304\nName: label, dtype: int64, 16:                      uid     label\n0  1000020_27...0513  0.086408\n4  1000086_2418_20160613  0.075930}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import os\\nimport numpy as np\\nimport pandas as pd...ve\\nfrom sklearn.preprocessing import MinMaxScaler', \"dfoff = pd.read_csv('ml100marathon-02-01/train_o...t(dfoff.shape)\\nprint(dftest.shape)\\ndfoff.head(20)\", '## Creat target label \\n\"\"\"\\nAccording to the defi...pply(label, axis=1)\\ndfoff[\"label\"].value_counts()', '# Generate features - weekday acquired coupon\\nde...ambda x : 1 if x >= 6 else 0 ) # apply to testset', \"weekdaycols = ['weekday_' + str(i) for i in rang...columns = weekdaycols\\ndftest[weekdaycols] = tmpdf\", '# Generate features - coupon discount and distan...= processData(dfoff)\\ndftest = processData(dftest)', \"# total coupon_counts\\n\\n# if there is a coupon id...erge(cc, on = 'User_id')\\n# print(raw_test.head())\", '## Naive model\\ndef split_train_valid(row, date_c...ve: {}\".format(len(valid), valid[\"label\"].sum()))', \"original_feature = ['distance_class',\\n          ...ols\\nprint(len(original_feature),original_feature)\", \"predictors = original_feature\\nprint(predictors)\\n...       data['label'])\\n    \\n    return grid_search\", 'model = check_model(train, predictors)', \"y_valid_pred = model.predict_proba(valid[predict...d.copy()\\nvalid1['pred_prob'] = y_valid_pred[:, 1]\", 'from sklearn.metrics import roc_auc_score, accur...{:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))', \"targetset = dftest.copy()\\nprint(targetset.shape)...red_prob'] = y_test_pred[:, 1]\\nprint(test1.shape)\", 'output = pd.concat((targetset[[\"User_id\", \"Coupo...is=1)\\noutput.reset_index(drop=True, inplace=True)', '### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN...el\"], index=False) # submission format\\nout.head()', \"# out.to_csv('baseline.csv',index=False)\", '## method 1 -> try to train all the data in repl..._01 = model_01.predict_proba(testset[predictors])', \"output_01 = output.copy()\\noutput_01['pred_prob']...ut_01.to_csv('all_data_training.csv',index=False)\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {2:     User_id  Merchant_id  Coupon_id Discount_rat...7         NaN  \n18  20160329.0  \n19         NaN  , 3:  0    710665\n-1    413773\n 1     36304\nName: label, dtype: int64, 16:                      uid     label\n0  1000020_27...0513  0.086408\n4  1000086_2418_20160613  0.075930}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\ken\\Desktop\\ML - midterm\\<ipython-input-20-75318c692910> in <module>()\n     32     grid_search = grid_search.fit(data[predictors], \n     33                                   data['label'])\n     34     \n     35     return grid_search\n     36 \n---> 37 model_02 = check_model_02(df, predictors)\n     38 \n     39 y_pred_02 = model_02.predict_proba(testset[predictors])\n\n...........................................................................\nC:\\Users\\ken\\Desktop\\ML - midterm\\<ipython-input-20-75318c692910> in check_model_02(data=         User_id  Merchant_id  Coupon_id Discoun... \n1160739      True  \n\n[746969 rows x 25 columns], predictors=['distance_class', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'total_coupon_received', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7'])\n     28         parameters, \n     29         cv=folder, \n     30         n_jobs=-1, \n     31         verbose=1)\n     32     grid_search = grid_search.fit(data[predictors], \n---> 33                                   data['label'])\n     34     \n     35     return grid_search\n     36 \n     37 model_02 = check_model_02(df, predictors)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=3, rand...ain_score='warn',\n       scoring=None, verbose=1), X=         distance_class  discount_type  discount...       0          0  \n\n[746969 rows x 14 columns], y=1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of StratifiedKFold(n_splits=3, random_state=None, shuffle=True)>\n        X =          distance_class  discount_type  discount...       0          0  \n\n[746969 rows x 14 columns]\n        y = 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 16 23:59:12 2019\nPID: 1436                   Python 3.7.0: C:\\Users\\ken\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), X=         distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], y=1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=memmap([     0,      1,      2, ..., 746959, 746966, 746968]), test=array([     5,      6,      8, ..., 746964, 746965, 746967]), verbose=1, parameters={'en__C': 0.001, 'en__tol': 0.0001}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'en__C': 0.001, 'en__tol': 0.0001}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'en__C': 0.001, 'en__tol': 0.0001})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'en__C': 0.001, 'en__tol': 0.0001}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'en__C': 0.001, 'en__tol': 0.0001})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'en__C': 0.001, 'en__tol': 0.0001}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **params={'en__C': 0.001, 'en__tol': 0.0001})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'en': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'en__alpha': 0.0001, 'en__average': False, 'en__class_weight': None, 'en__epsilon': 0.1, 'en__eta0': 0.0, 'en__fit_intercept': True, 'en__l1_ratio': 0.15, 'en__learning_rate': 'optimal', 'en__loss': 'log', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.001, 'tol': 0.0001}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.001, 'tol': 0.0001})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.001, 'tol': 0.0001}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.001, 'tol': 0.0001})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=100, n_iter=None,\n       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 282, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\", line 77, in set_params\n    super(BaseSGD, self).set_params(*args, **kwargs)\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=100, n_iter=None,\n       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 16 23:59:12 2019\nPID: 1436                   Python 3.7.0: C:\\Users\\ken\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), X=         distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], y=1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=memmap([     0,      1,      2, ..., 746959, 746966, 746968]), test=array([     5,      6,      8, ..., 746964, 746965, 746967]), verbose=1, parameters={'en__C': 0.001, 'en__tol': 0.0001}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'en__C': 0.001, 'en__tol': 0.0001}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'en__C': 0.001, 'en__tol': 0.0001})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'en__C': 0.001, 'en__tol': 0.0001}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'en__C': 0.001, 'en__tol': 0.0001})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'en__C': 0.001, 'en__tol': 0.0001}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **params={'en__C': 0.001, 'en__tol': 0.0001})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'en': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'en__alpha': 0.0001, 'en__average': False, 'en__class_weight': None, 'en__epsilon': 0.1, 'en__eta0': 0.0, 'en__fit_intercept': True, 'en__l1_ratio': 0.15, 'en__learning_rate': 'optimal', 'en__loss': 'log', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.001, 'tol': 0.0001}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.001, 'tol': 0.0001})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.001, 'tol': 0.0001}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.001, 'tol': 0.0001})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=100, n_iter=None,\n       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Jun 16 23:59:12 2019\nPID: 1436                   Python 3.7.0: C:\\Users\\ken\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), X=         distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], y=1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=memmap([     0,      1,      2, ..., 746959, 746966, 746968]), test=array([     5,      6,      8, ..., 746964, 746965, 746967]), verbose=1, parameters={'en__C': 0.001, 'en__tol': 0.0001}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'en__C': 0.001, 'en__tol': 0.0001}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'en__C': 0.001, 'en__tol': 0.0001})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'en__C': 0.001, 'en__tol': 0.0001}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'en__C': 0.001, 'en__tol': 0.0001})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'en__C': 0.001, 'en__tol': 0.0001}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **params={'en__C': 0.001, 'en__tol': 0.0001})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'en': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'en__alpha': 0.0001, 'en__average': False, 'en__class_weight': None, 'en__epsilon': 0.1, 'en__eta0': 0.0, 'en__fit_intercept': True, 'en__l1_ratio': 0.15, 'en__learning_rate': 'optimal', 'en__loss': 'log', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.001, 'tol': 0.0001}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.001, 'tol': 0.0001})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.001, 'tol': 0.0001}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.001, 'tol': 0.0001})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=100, n_iter=None,\n       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-75318c692910>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mmodel_02\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_model_02\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0my_pred_02\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_02\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-75318c692910>\u001b[0m in \u001b[0;36mcheck_model_02\u001b[1;34m(data, predictors)\u001b[0m\n\u001b[0;32m     31\u001b[0m         verbose=1)\n\u001b[0;32m     32\u001b[0m     grid_search = grid_search.fit(data[predictors], \n\u001b[1;32m---> 33\u001b[1;33m                                   data['label'])\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 640\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000293A38411E0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\k...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000293A38411E0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\k...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    494         if self.poller is not None:\n    495             self.poller.start()\n    496         self.kernel.start()\n    497         self.io_loop = ioloop.IOLoop.current()\n    498         try:\n--> 499             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    500         except KeyboardInterrupt:\n    501             pass\n    502 \n    503 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...0293D4E6B840>))>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...0293D4E6B840>))>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x00000293D4E6B840>),)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x00000293D4E6B840>))\n    753         \"\"\"Runs a callback with error handling.\n    754 \n    755         For use in subclasses.\n    756         \"\"\"\n    757         try:\n--> 758             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x00000293D4E6B840>)\n    759             if ret is not None:\n    760                 from tornado import gen\n    761                 # Functions that return Futures typically swallow all\n    762                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 16, 15, 53, 7, 174938, tzinfo=tzutc()), 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'session': '69c95fcc03084f908798f6f45cf8d885', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'69c95fcc03084f908798f6f45cf8d885']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 16, 15, 53, 7, 174938, tzinfo=tzutc()), 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'session': '69c95fcc03084f908798f6f45cf8d885', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'69c95fcc03084f908798f6f45cf8d885'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 6, 16, 15, 53, 7, 174938, tzinfo=tzutc()), 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'session': '69c95fcc03084f908798f6f45cf8d885', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '6694cd8cc0494830958c656b52d0e49f', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = '## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='## method 2 -> modify model - change scaler + lo..._02 = model_02.predict_proba(testset[predictors])', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.FunctionDef object>, <_ast.Assign object>, <_ast.Assign object>], cell_name='<ipython-input-20-75318c692910>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 293c1b359e8, executio...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x00000293C1B1C810, file \"<ipython-input-20-75318c692910>\", line 37>\n        result = <ExecutionResult object at 293c1b359e8, executio...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x00000293C1B1C810, file \"<ipython-input-20-75318c692910>\", line 37>, result=<ExecutionResult object at 293c1b359e8, executio...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x00000293C1B1C810, file \"<ipython-input-20-75318c692910>\", line 37>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import os\\nimport numpy as np\\nimport pandas as pd...ve\\nfrom sklearn.preprocessing import MinMaxScaler', \"dfoff = pd.read_csv('ml100marathon-02-01/train_o...t(dfoff.shape)\\nprint(dftest.shape)\\ndfoff.head(20)\", '## Creat target label \\n\"\"\"\\nAccording to the defi...pply(label, axis=1)\\ndfoff[\"label\"].value_counts()', '# Generate features - weekday acquired coupon\\nde...ambda x : 1 if x >= 6 else 0 ) # apply to testset', \"weekdaycols = ['weekday_' + str(i) for i in rang...columns = weekdaycols\\ndftest[weekdaycols] = tmpdf\", '# Generate features - coupon discount and distan...= processData(dfoff)\\ndftest = processData(dftest)', \"# total coupon_counts\\n\\n# if there is a coupon id...erge(cc, on = 'User_id')\\n# print(raw_test.head())\", '## Naive model\\ndef split_train_valid(row, date_c...ve: {}\".format(len(valid), valid[\"label\"].sum()))', \"original_feature = ['distance_class',\\n          ...ols\\nprint(len(original_feature),original_feature)\", \"predictors = original_feature\\nprint(predictors)\\n...       data['label'])\\n    \\n    return grid_search\", 'model = check_model(train, predictors)', \"y_valid_pred = model.predict_proba(valid[predict...d.copy()\\nvalid1['pred_prob'] = y_valid_pred[:, 1]\", 'from sklearn.metrics import roc_auc_score, accur...{:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))', \"targetset = dftest.copy()\\nprint(targetset.shape)...red_prob'] = y_test_pred[:, 1]\\nprint(test1.shape)\", 'output = pd.concat((targetset[[\"User_id\", \"Coupo...is=1)\\noutput.reset_index(drop=True, inplace=True)', '### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN...el\"], index=False) # submission format\\nout.head()', \"# out.to_csv('baseline.csv',index=False)\", '## method 1 -> try to train all the data in repl..._01 = model_01.predict_proba(testset[predictors])', \"output_01 = output.copy()\\noutput_01['pred_prob']...ut_01.to_csv('all_data_training.csv',index=False)\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {2:     User_id  Merchant_id  Coupon_id Discount_rat...7         NaN  \n18  20160329.0  \n19         NaN  , 3:  0    710665\n-1    413773\n 1     36304\nName: label, dtype: int64, 16:                      uid     label\n0  1000020_27...0513  0.086408\n4  1000086_2418_20160613  0.075930}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import os\\nimport numpy as np\\nimport pandas as pd...ve\\nfrom sklearn.preprocessing import MinMaxScaler', \"dfoff = pd.read_csv('ml100marathon-02-01/train_o...t(dfoff.shape)\\nprint(dftest.shape)\\ndfoff.head(20)\", '## Creat target label \\n\"\"\"\\nAccording to the defi...pply(label, axis=1)\\ndfoff[\"label\"].value_counts()', '# Generate features - weekday acquired coupon\\nde...ambda x : 1 if x >= 6 else 0 ) # apply to testset', \"weekdaycols = ['weekday_' + str(i) for i in rang...columns = weekdaycols\\ndftest[weekdaycols] = tmpdf\", '# Generate features - coupon discount and distan...= processData(dfoff)\\ndftest = processData(dftest)', \"# total coupon_counts\\n\\n# if there is a coupon id...erge(cc, on = 'User_id')\\n# print(raw_test.head())\", '## Naive model\\ndef split_train_valid(row, date_c...ve: {}\".format(len(valid), valid[\"label\"].sum()))', \"original_feature = ['distance_class',\\n          ...ols\\nprint(len(original_feature),original_feature)\", \"predictors = original_feature\\nprint(predictors)\\n...       data['label'])\\n    \\n    return grid_search\", 'model = check_model(train, predictors)', \"y_valid_pred = model.predict_proba(valid[predict...d.copy()\\nvalid1['pred_prob'] = y_valid_pred[:, 1]\", 'from sklearn.metrics import roc_auc_score, accur...{:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))', \"targetset = dftest.copy()\\nprint(targetset.shape)...red_prob'] = y_test_pred[:, 1]\\nprint(test1.shape)\", 'output = pd.concat((targetset[[\"User_id\", \"Coupo...is=1)\\noutput.reset_index(drop=True, inplace=True)', '### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN...el\"], index=False) # submission format\\nout.head()', \"# out.to_csv('baseline.csv',index=False)\", '## method 1 -> try to train all the data in repl..._01 = model_01.predict_proba(testset[predictors])', \"output_01 = output.copy()\\noutput_01['pred_prob']...ut_01.to_csv('all_data_training.csv',index=False)\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {2:     User_id  Merchant_id  Coupon_id Discount_rat...7         NaN  \n18  20160329.0  \n19         NaN  , 3:  0    710665\n-1    413773\n 1     36304\nName: label, dtype: int64, 16:                      uid     label\n0  1000020_27...0513  0.086408\n4  1000086_2418_20160613  0.075930}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\ken\\Desktop\\ML - midterm\\<ipython-input-20-75318c692910> in <module>()\n     32     grid_search = grid_search.fit(data[predictors], \n     33                                   data['label'])\n     34     \n     35     return grid_search\n     36 \n---> 37 model_02 = check_model_02(df, predictors)\n     38 \n     39 y_pred_02 = model_02.predict_proba(testset[predictors])\n\n...........................................................................\nC:\\Users\\ken\\Desktop\\ML - midterm\\<ipython-input-20-75318c692910> in check_model_02(data=         User_id  Merchant_id  Coupon_id Discoun... \n1160739      True  \n\n[746969 rows x 25 columns], predictors=['distance_class', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'total_coupon_received', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7'])\n     28         parameters, \n     29         cv=folder, \n     30         n_jobs=-1, \n     31         verbose=1)\n     32     grid_search = grid_search.fit(data[predictors], \n---> 33                                   data['label'])\n     34     \n     35     return grid_search\n     36 \n     37 model_02 = check_model_02(df, predictors)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=StratifiedKFold(n_splits=3, rand...ain_score='warn',\n       scoring=None, verbose=1), X=         distance_class  discount_type  discount...       0          0  \n\n[746969 rows x 14 columns], y=1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of StratifiedKFold(n_splits=3, random_state=None, shuffle=True)>\n        X =          distance_class  discount_type  discount...       0          0  \n\n[746969 rows x 14 columns]\n        y = 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Jun 16 23:59:12 2019\nPID: 1436                   Python 3.7.0: C:\\Users\\ken\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]),          distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], 1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, {'score': <function _passthrough_scorer>}, memmap([     0,      1,      2, ..., 746959, 746966, 746968]), array([     5,      6,      8, ..., 746964, 746965, 746967]), 1, {'en__C': 0.001, 'en__tol': 0.0001})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), X=         distance_class  discount_type  discount...         0          0\n\n[746969 rows x 14 columns], y=1          0\n2          0\n3          0\n4        ...39    1\nName: label, Length: 746969, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=memmap([     0,      1,      2, ..., 746959, 746966, 746968]), test=array([     5,      6,      8, ..., 746964, 746965, 746967]), verbose=1, parameters={'en__C': 0.001, 'en__tol': 0.0001}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'en__C': 0.001, 'en__tol': 0.0001}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'en__C': 0.001, 'en__tol': 0.0001})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'en__C': 0.001, 'en__tol': 0.0001}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'en__C': 0.001, 'en__tol': 0.0001})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'en__C': 0.001, 'en__tol': 0.0001}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('ss', MinMaxS...e=True, tol=None, verbose=0, warm_start=False))]), **params={'en__C': 0.001, 'en__tol': 0.0001})\n    277                 nested_params[key][sub_key] = value\n    278             else:\n    279                 setattr(self, key, value)\n    280 \n    281         for key, sub_params in nested_params.items():\n--> 282             valid_params[key].set_params(**sub_params)\n        valid_params = {'en': SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), 'en__alpha': 0.0001, 'en__average': False, 'en__class_weight': None, 'en__epsilon': 0.1, 'en__eta0': 0.0, 'en__fit_intercept': True, 'en__l1_ratio': 0.15, 'en__learning_rate': 'optimal', 'en__loss': 'log', ...}\n        key.set_params = undefined\n        sub_params = {'C': 0.001, 'tol': 0.0001}\n    283 \n    284         return self\n    285 \n    286     def __repr__(self):\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), *args=(), **kwargs={'C': 0.001, 'tol': 0.0001})\n     72         # current tests expect init to do parameter validation\n     73         # but we are not allowed to set attributes\n     74         self._validate_params(set_max_iter=False)\n     75 \n     76     def set_params(self, *args, **kwargs):\n---> 77         super(BaseSGD, self).set_params(*args, **kwargs)\n        self.set_params = <bound method BaseSGD.set_params of SGDClassifie...fle=True, tol=None, verbose=0, warm_start=False)>\n        args = ()\n        kwargs = {'C': 0.001, 'tol': 0.0001}\n     78         self._validate_params(set_max_iter=False)\n     79         return self\n     80 \n     81     @abstractmethod\n\n...........................................................................\nC:\\Users\\ken\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False), **params={'C': 0.001, 'tol': 0.0001})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'C'\n        self = SGDClassifier(alpha=0.0001, average=False, class...ffle=True, tol=None, verbose=0, warm_start=False)\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter C for estimator SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=100, n_iter=None,\n       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "## method 2 -> modify model - change scaler + logistic regression\n",
    "\n",
    "def check_model_02(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', MinMaxScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__C': [ 0.001, 0.01, 0.1, 1.0 ],\n",
    "        'en__tol': [ 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search\n",
    "\n",
    "model_02 = check_model_02(df, predictors)\n",
    "\n",
    "y_pred_02 = model_02.predict_proba(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_02 = output.copy()\n",
    "output_02['pred_prob'] = y_pred_02[:, 1]\n",
    "out_02 = output_02.groupby(\"uid\", as_index=False).mean()\n",
    "out_02 = out_02[[\"uid\", \"pred_prob\"]]\n",
    "out_02.columns = [\"uid\", \"label\"]\n",
    "print(out_02.head())\n",
    "# out_02.to_csv('MM_scaler.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 3 -> try\n",
    "\n",
    "out_03 = out_01.copy()\n",
    "\n",
    "out_03['label'] = out_03['label']*3\n",
    "\n",
    "# out_03.to_csv('try.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 4 -> issues: sample data bias \n",
    "\n",
    "df_04 = df[df['label'] == 1].append(df[df['label'] == 0].head(60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   13.6s finished\n"
     ]
    }
   ],
   "source": [
    "model_04 = check_model(df_04, predictors)\n",
    "\n",
    "y_pred_04 = model_04.predict_proba(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.618598\n",
      "1  1000020_8192_20160513  0.567344\n",
      "2  1000065_1455_20160527  0.529289\n",
      "3  1000085_8067_20160513  0.518447\n",
      "4  1000086_2418_20160613  0.469308\n"
     ]
    }
   ],
   "source": [
    "output_04 = output.copy()\n",
    "output_04['pred_prob'] = y_pred_04[:, 1]\n",
    "out_04 = output_04.groupby(\"uid\", as_index=False).mean()\n",
    "out_04 = out_04[[\"uid\", \"pred_prob\"]]\n",
    "out_04.columns = [\"uid\", \"label\"]\n",
    "print(out_04.head())\n",
    "# out_04.to_csv('unbias_training_set.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## method 5 -> issues: sample data bias . try\n",
    "\n",
    "out_05 = out_04.copy()\n",
    "\n",
    "out_05['label'][out_05['label']>=0.5] = 1\n",
    "out_05['label'][out_05['label']<0.5] = 0\n",
    "\n",
    "# out_05.to_csv('unbias_training_set_binary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 6 -> deep learning\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import random_mini_batches  ### 參考使用 Coursera 吳恩達老師上課教材\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y,None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 TensorFlow 模型(幾層神經網路) 及 初始化神經元參數\n",
    "def initialize_parameters():\n",
    "    \n",
    "    # 設定 random seeds → 避免每次訓練結果都不一樣\n",
    "    tf.set_random_seed(1)                   \n",
    "    \n",
    "    # 設共三層神經\n",
    "    W1 = tf.get_variable(\"W1\", [8,14], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [8,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [4,8], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [4,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,4], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 TensorFlow 向前傳播 計算公式\n",
    "def forward_propagation(X, parameters):\n",
    "    ### LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> Sigmoid\n",
    "    \n",
    "    # 抓取神經元權重參數 (parameters)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "   \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                  # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                 # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算模型的 成本 (Cost) → 模型的好壞\n",
    "\n",
    "def class_balanced_sigmoid_cross_entropy(logits, label, name='cross_entropy_loss'):\n",
    "    y = tf.cast(label, tf.float32)\n",
    "    count_neg = tf.reduce_sum(1. - y) # the number of 0 in y\n",
    "    count_pos = tf.reduce_sum(y) # the number of 1 in y (less than count_neg)\n",
    "    beta = count_neg / (count_neg + count_pos)\n",
    "    pos_weight = beta / (1 - beta)\n",
    "    cost = tf.nn.weighted_cross_entropy_with_logits(logits, y, pos_weight)\n",
    "    cost = tf.reduce_mean(cost * (1 - beta), name=name)\n",
    "    return cost\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    Z3 = tf.sigmoid(Z3)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "#     cost = class_balanced_sigmoid_cross_entropy(logits = logits, label = labels)\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合全部函數，建立機器學習模型\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 200, minibatch_size = 1024, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                          \n",
    "    (n_x, m) = X_train.shape                          \n",
    "    n_y = Y_train.shape[0]                            \n",
    "    costs = []                                        \n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # 初始化神經元權重參數\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # 向前傳播\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # 成本函數 → 計算成本\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # 反向傳播 (設定最佳化計算函數→最小化成本) \n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # 初始化全部變數\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # 啟動 TensorFlow \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        # 反覆訓練\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            epoch_cost = 0.                       \n",
    "            num_minibatches = int(m / minibatch_size) \n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "  \n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print 每 100 次訓練的成本\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # 視覺化 cost 變化\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # 儲存最後訓練出來的模型參數\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # 計算模型預測的能力\n",
    "        correct_prediction = tf.equal(tf.round(tf.nn.sigmoid(Z3)), Y)\n",
    "\n",
    "        # 計算模型對於測試集的準確率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[predictors]\n",
    "mm = MinMaxScaler()\n",
    "mm_target = ['discount_man','discount_jian','Distance','total_coupon_received']\n",
    "\n",
    "df_dnn = df[predictors].copy()\n",
    "Y = df['label'].copy()\n",
    "\n",
    "df_dnn[mm_target] = mm.fit_transform(df_dnn[mm_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14, 522878)\n",
      "Y_train shape: (1, 522878)\n",
      "X_test shape: (14, 224091)\n",
      "Y_test shape: (1, 224091)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_dnn, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.transpose().values\n",
    "X_test = X_test.transpose().values\n",
    "Y_train = Y_train.values.reshape(1,len(Y_train))\n",
    "Y_test = Y_test.values.reshape(1,len(Y_test))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ken\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Cost after epoch 0: 0.855308\n",
      "Cost after epoch 100: 0.832388\n",
      "Cost after epoch 200: 0.810699\n",
      "Cost after epoch 300: 0.790174\n",
      "Cost after epoch 400: 0.771453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.9513309\n",
      "Test Accuracy: 0.9515554\n"
     ]
    }
   ],
   "source": [
    "parameters_DNN = model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 500, minibatch_size = 522878, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用訓練過後的模型，進行預測\n",
    "def predict_new(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [14, 306313])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict_new(x, params)\n",
    "    p = tf.sigmoid(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict_new(X, parameters):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.084036\n",
      "1  1000020_8192_20160513  0.258802\n",
      "2  1000065_1455_20160527  0.259890\n",
      "3  1000085_8067_20160513  0.258380\n",
      "4  1000086_2418_20160613  0.144062\n"
     ]
    }
   ],
   "source": [
    "test_dnn = testset[predictors].copy()\n",
    "test_dnn[mm_target] = mm.fit_transform(test_dnn[mm_target])\n",
    "test_dnn =  test_dnn.transpose().values\n",
    "\n",
    "dnn_pred = predict_new(test_dnn, parameters_DNN)\n",
    "dnn_pred = dnn_pred.transpose()\n",
    "\n",
    "output_06 = output.copy()\n",
    "output_06['pred_prob'] = dnn_pred\n",
    "out_06 = output_06.groupby(\"uid\", as_index=False).mean()\n",
    "out_06 = out_06[[\"uid\", \"pred_prob\"]]\n",
    "out_06.columns = [\"uid\", \"label\"]\n",
    "print(out_06.head())\n",
    "out_06.to_csv('DNN_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14, 57782)\n",
      "Y_train shape: (1, 57782)\n",
      "X_test shape: (14, 38522)\n",
      "Y_test shape: (1, 38522)\n"
     ]
    }
   ],
   "source": [
    "## unbias data sampling - 07\n",
    "# df_04[predictors]\n",
    "# mm = MinMaxScaler()\n",
    "# mm_target = ['discount_man','discount_jian','Distance','weekday']\n",
    "\n",
    "df_dnn_07 = df_04[predictors].copy()\n",
    "Y_07 = df_04['label'].copy()\n",
    "\n",
    "df_dnn_07[mm_target] = mm.fit_transform(df_dnn_07[mm_target])\n",
    "\n",
    "X_train_07, X_test_07, Y_train_07, Y_test_07 = train_test_split(df_dnn_07, Y_07, test_size=0.4, random_state=42)\n",
    "\n",
    "X_train_07 = X_train_07.transpose().values\n",
    "X_test_07 = X_test_07.transpose().values\n",
    "Y_train_07 = Y_train_07.values.reshape(1,len(Y_train_07))\n",
    "Y_test_07 = Y_test_07.values.reshape(1,len(Y_test_07))\n",
    "print (\"X_train shape: \" + str(X_train_07.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train_07.shape))\n",
    "print (\"X_test shape: \" + str(X_test_07.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test_07.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.745814\n",
      "Cost after epoch 100: 0.683394\n",
      "Cost after epoch 200: 0.679919\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcXXV9//HXOzNzZ01mJskQyErAsEpIMAVxoVg3VAq1bsQNrZVqxba01R+0Vin+/NWlilppK7VCXQoiWkWgICIKKiADJEASQsKaMdskmUkyM5kt+fz+OGeSmzt3cmdgbu4s7+fjcR5zz/d8z7mfbzJzP/d8v+ecryICMzOzQ5lS6gDMzGzsc7IwM7OCnCzMzKwgJwszMyvIycLMzApysjAzs4KcLGzCk/S/ki4sdRxm45mThRWNpGckvabUcUTEGyLiv0odB4CkX0j608PwPpWSvilpl6TNkv66QP1L0no70/0qs7YdLekuSV2SHs/9Py2w76clPSqpX9Llo95QO2ycLGxck1Re6hgGjKVYgMuBRcAC4FXAxyWdk6+ipNcDlwKvBo4GjgH+MavKdcDDwAzg74EbJTUNc9/1wMeBW0alVVYyThZWEpLOlbRCUruk30hanLXtUklPStotabWkN2dte5+kX0u6UtIO4PK07FeS/llSm6SnJb0ha5/93+aHUXehpLvT9/6ZpKskfWeINpwtqUXS/5G0GbhGUqOkmyW1pse/WdLctP5ngFcCX5PUIelrafkJku6QtEPSWklvH4V/4vcCn46ItohYA/wH8L4h6l4I/GdErIqINuDTA3UlHQecBnwqIvZExA+AR4G3FNoXICL+KyL+F9g9Cm2yEnKysMNO0mnAN4E/I/m2+nXgpqzuiydJPlTrSb6lfkfSUVmHOAN4CjgC+ExW2VpgJvB54D8laYgQDlX3v4HfpnFdDrynQHOOBKaTfIO/iORv6pp0fT6wB/gaQET8PXAPcHFE1EXExZJqgTvS9z0CWA78q6ST872ZpH9NE2y+5ZG0TiMwG1iZtetKIO8x0/LcurMkzUi3PRURu3O2nzyMfW0CcbKwUvgg8PWIuD8i9qbjCT3ASwEi4vsRsTEi9kXE94B1wOlZ+2+MiH+JiP6I2JOWPRsR/xERe4H/Ao4CZg3x/nnrSpoP/B7wyYjojYhfATcVaMs+km/dPek37+0R8YOI6Eo/YD8D/P4h9j8XeCYirknb8xDwA+Ct+SpHxJ9HRMMQy8DZWV36c2fWrjuBqUPEUJenLmn93G25xzrUvjaBOFlYKSwA/ib7WzEwj+TbMJLem9VF1Q68mOQsYMCGPMfcPPAiIrrSl3V56h2q7mxgR1bZUO+VrTUiugdWJNVI+rqkZyXtAu4GGiSVDbH/AuCMnH+Ld5GcsTxfHenPaVll0xi6K6gjT13S+rnbco91qH1tAnGysFLYAHwm51txTURcJ2kBSf/6xcCMiGgAHgOyu5SK9ajkTcB0STVZZfMK7JMby98AxwNnRMQ04Ky0XEPU3wD8Muffoi4iPpzvzST9ezrekW9ZBZCOHWwCTs3a9VRg1RBtWJWn7paI2J5uO0bS1Jztq4axr00gThZWbBWSqrKWcpJk8CFJZyhRK+lN6QdSLckHaiuApPeTnFkUXUQ8CzSTDJpnJJ0J/OEIDzOVZJyiXdJ04FM527eQXDE04GbgOEnvkVSRLr8n6cQhYvxQmkzyLdljEt8CPpEOuJ9A0vV37RAxfwv4gKST0vGOTwzUjYgngBXAp9L/vzcDi0m6yg65L0DaniqSz5ry9BhDnWXZGOZkYcV2K8mH58ByeUQ0k3x4fQ1oI7m88n0AEbEa+CJwL8kH6ynArw9jvO8CzgS2A/8X+B7JeMpwfRmoBrYB9wG35Wz/CvDW9Eqpr6bjGq8DLgA2knSRfQ6o5IX5FMmFAs8CvwS+EBG3AUian56JzAdIyz8P3JXWf5aDk9wFwDKS/6vPAm+NiNZh7vsfJP/vy0kuu91D4YsGbAySJz8yG5qk7wGPR0TuGYLZpOIzC7MsaRfQsZKmKLmJ7XzgR6WOy6zUxtIdp2ZjwZHAD0nus2gBPhwRD5c2JLPSczeUmZkV5G4oMzMraMJ0Q82cOTOOPvroUodhZjauPPjgg9sioqlQvQmTLI4++miam5tLHYaZ2bgi6dnh1HM3lJmZFeRkYWZmBTlZmJlZQU4WZmZWkJOFmZkV5GRhZmYFOVmYmVlBkz5ZdPT086U7nmDFhvZSh2JmNmZN+mTRv3cfX71zHQ8/11bqUMzMxqxJnyxqMslN7J09/SWOxMxs7Jr0ySJTPoVM2RQ6evaWOhQzszFr0icLgNrKMp9ZmJkdgpMFUFtZ7mRhZnYIThZAXWU5nb1OFmZmQ3GyAGoyZXR6zMLMbEhOFiTdUB3uhjIzG5KTBWk3lJOFmdmQnCzwALeZWSFOFgwMcHvMwsxsKE4WDAxw9xMRpQ7FzGxMcrIg6Ybq3xf09O8rdShmZmOSkwVJNxT4+VBmZkMparKQdI6ktZLWS7o0z/YrJa1Ilycktedsnybpd5K+Vsw4a/cnC49bmJnlU16sA0sqA64CXgu0AA9IuikiVg/UiYhLsup/FFiac5hPA78sVowD6irLAHwXt5nZEIp5ZnE6sD4inoqIXuB64PxD1F8OXDewIuklwCzgp0WMEfBjys3MCilmspgDbMhab0nLBpG0AFgI/DxdnwJ8EfjYod5A0kWSmiU1t7a2Pu9AB7qhfBe3mVl+xUwWylM21LWpFwA3RsTAoMGfA7dGxIYh6icHi7g6IpZFxLKmpqbnHWidxyzMzA6paGMWJGcS87LW5wIbh6h7AfCRrPUzgVdK+nOgDshI6oiIQYPko6F2YMzCZxZmZnkVM1k8ACyStBD4HUlCeGduJUnHA43AvQNlEfGurO3vA5YVK1HAgTMLd0OZmeVXtG6oiOgHLgZuB9YAN0TEKklXSDovq+py4Poo4e3TAwPcXb4ayswsr2KeWRARtwK35pR9Mmf98gLHuBa4dpRDO4jn4TYzOzTfwZ3yPNxmZkNzskj5MeVmZkNzskjVebY8M7MhOVmkajJldHlOCzOzvJwsUp6H28xsaE4WKc/DbWY2NCeLlAe4zcyG5mSR8gC3mdnQnCxStZVldPbu9TzcZmZ5OFmkajLl7PU83GZmeTlZpDwPt5nZ0JwsUp6H28xsaE4WqYF5uD3IbWY2mJNFav+ZhR9TbmY2iJNFamBOC49ZmJkN5mSR8jzcZmZDc7JIeR5uM7OhOVmkPA+3mdnQnCxSHrMwMxuak0Vq/zzcvhrKzGyQoiYLSedIWitpvaRL82y/UtKKdHlCUntavkDSg2n5KkkfKmacA2ory+jyALeZ2SDlxTqwpDLgKuC1QAvwgKSbImL1QJ2IuCSr/keBpenqJuBlEdEjqQ54LN13Y7HiBT+m3MxsKMU8szgdWB8RT0VEL3A9cP4h6i8HrgOIiN6I6EnLK4sc535+TLmZWX7F/BCeA2zIWm9JywaRtABYCPw8q2yepEfSY3wu31mFpIskNUtqbm1tfcEB11aW+w5uM7M8ipkslKdsqMkiLgBujIj9AwYRsSEiFgMvAi6UNGvQwSKujohlEbGsqanpBQdckymjw2MWZmaDFDNZtADzstbnAkONOVxA2gWVKz2jWAW8clSjy6Ouspwud0OZmQ1SzGTxALBI0kJJGZKEcFNuJUnHA43AvVllcyVVp68bgZcDa4sYK+ABbjOzoRTtaqiI6Jd0MXA7UAZ8MyJWSboCaI6IgcSxHLg+Dp7P9ETgi5KCpDvrnyPi0WLFOsAD3GZm+RUtWQBExK3ArTlln8xZvzzPfncAi4sZWz7Z83BL+YZczMwmJ9/BncXzcJuZ5edkkcXzcJuZ5edkkcXzcJuZ5edkkcXzcJuZ5edkkcXzcJuZ5edkkaXWEyCZmeXlZJGl1hMgmZnl5WSRZWAebs9pYWZ2MCeLLJ6H28wsPyeLLLW+z8LMLC8niywVZVPIlHsebjOzXE4WOWozZT6zMDPL4WSRo7ay3APcZmY5nCxy+DHlZmaDOVnk8DzcZmaDOVnkqK0s9zzcZmY5nCxyeIDbzGwwJ4scnofbzGwwJ4scdU4WZmaDOFnkyJ6H28zMEkVNFpLOkbRW0npJl+bZfqWkFenyhKT2tHyJpHslrZL0iKR3FDPObLWVnofbzCxXebEOLKkMuAp4LdACPCDppohYPVAnIi7Jqv9RYGm62gW8NyLWSZoNPCjp9ohoL1a8AwYeU97R009VRVmx387MbFwo5pnF6cD6iHgqInqB64HzD1F/OXAdQEQ8ERHr0tcbga1AUxFj3c8PEzQzG6yYyWIOsCFrvSUtG0TSAmAh8PM8204HMsCTebZdJKlZUnNra+uoBD0wD3en77UwM9uvmMlCecqGGjW+ALgxIg76hJZ0FPBt4P0RMWgQISKujohlEbGsqWl0Tjw8D7eZ2WDFTBYtwLys9bnAxiHqXkDaBTVA0jTgFuATEXFfUSLMw/Nwm5kNVsxk8QCwSNJCSRmShHBTbiVJxwONwL1ZZRngf4BvRcT3ixjjIJ6H28xssKIli4joBy4GbgfWADdExCpJV0g6L6vqcuD6OPjGhrcDZwHvy7q0dkmxYs1Wu3/MwsnCzGxA0S6dBYiIW4Fbc8o+mbN+eZ79vgN8p5ixDaVu/9VQHuA2MxvgO7hz+NJZM7PBnCxyeB5uM7PBnCzy8MMEzcwO5mSRR02mzGMWZmZZnCzy8DzcZmYHc7LIo7aynC6PWZiZ7edkkYfn4TYzO5iTRR51lZ6H28wsm5NFHjUZXw1lZpbNySIPD3CbmR1sWMlC0tuGUzZR1FaW0eV5uM3M9hvumcVlwyybEDwPt5nZwQ75IEFJbwDeCMyR9NWsTdOACdtPU1fpebjNzLIVeursRqAZOA94MKt8N3BJsYIqtZqsOS1m1lWWOBozs9I7ZLKIiJXASkn/HRF9AJIagXkR0XY4AiyFgXm4PchtZpYY7pjFHZKmSZoOrASukfSlIsZVUrWe08LM7CDDTRb1EbEL+GPgmoh4CfCa4oVVWvuThR/5YWYGDD9ZlEs6imS605uLGM+YUOcJkMzMDjLcZHEFyVzaT0bEA5KOAdYVL6zSqsl4Hm4zs2zDmoM7Ir4PfD9r/SngLcUKqtQOXDrrMQszMxj+HdxzJf2PpK2Stkj6gaS5w9jvHElrJa2XdGme7VdKWpEuT0hqz9p2m6R2SYe928vzcJuZHWy43VDXADcBs4E5wE/SsiFJKgOuAt4AnAQsl3RSdp2IuCQilkTEEuBfgB9mbf4C8J5hxjeqBubh9gC3mVliuMmiKSKuiYj+dLkWaCqwz+nA+oh4KiJ6geuB8w9Rfzlw3cBKRNxJcvNfSTTWVLB1V0+p3t7MbEwZbrLYJundksrS5d3A9gL7zAE2ZK23pGWDSFoALAR+Psx4Bva7SFKzpObW1taR7FrQKXMaWLmhvXBFM7NJYLjJ4k9ILpvdDGwC3gq8v8A+ylM21GNcLwBujIgRjShHxNURsSwiljU1FTrRGZnTFjTw1LZO2jp7R/W4Zmbj0XCTxaeBCyOiKSKOIEkelxfYpwWYl7U+l+RZU/lcQFYX1FiwdF4jACt8dmFmNuxksTj7WVARsQNYWmCfB4BFkhZKypAkhJtyK0k6HmgE7h1mLIfF4rn1TBE8/NyEfQSWmdmwDTdZTEkfIAhA+oyoQg8h7AcuJrmZbw1wQ0SsknSFpPOyqi4Hro+cmYYk3UNyb8erJbVIev0wYx0VtZXlnHDkNB56zmcWZmbDuikP+CLwG0k3kow7vB34TKGdIuJW4Nacsk/mrF8+xL6vHGZsRbN0fgM/XrGRvfuCsin5hmDMzCaHYZ1ZRMS3SO7Y3gK0An8cEd8uZmBjwdL5jXT09PNka0epQzEzK6nhnlkQEauB1UWMZcw5bX4DkIxbHDdraomjMTMrneGOWUxKC2fWUl9dwUPPetzCzCY3J4tDkMTS+Q08vMFXRJnZ5OZkUcBp8xtZt7WDXd19pQ7FzKxknCwKWDq/gQj86A8zm9ScLAo4dV4DEjzs+y3MbBJzsihgWlUFi46o853cZjapOVkMw9J5jTy8oZ2cm8zNzCYNJ4thWDq/gfauPp7e1lnqUMzMSsLJYhhOW5A8FsvjFmY2WTlZDMOLmuqYWlnu+y3MbNJyshiGKVPEqfMafGZhZpOWk8UwnTa/gcc376art7/UoZiZHXZOFsO0dH4je/cFj7TsLHUoZmaHnZPFMC2ZN/AEWndFmdnk42QxTI21GY6ZWcuda7awb5/vtzCzycXJYgT+5BULaX62jS/fua7UoZiZHVZOFiPwrjPm87aXzOWrd67j9lWbSx2Omdlh42QxApL49B+9mFPn1vM3N6xk/dbdpQ7JzOywKGqykHSOpLWS1ku6NM/2KyWtSJcnJLVnbbtQ0rp0ubCYcY5EVUUZ//bul1BVMYWLvvWg57kws0mhaMlCUhlwFfAG4CRguaSTsutExCURsSQilgD/Avww3Xc68CngDOB04FOSGosV60jNbqjmqneexnM7uvjr763wgLeZTXjFPLM4HVgfEU9FRC9wPXD+IeovB65LX78euCMidkREG3AHcE4RYx2xM46ZwT+cexI/W7OVL96x1k+kNbMJrZjJYg6wIWu9JS0bRNICYCHw85HsK+kiSc2SmltbW0cl6JF475kLeMeyeVx115P8xfUr6Ojx3d1mNjEVM1koT9lQX78vAG6MiL0j2Tciro6IZRGxrKmp6XmG+fxJ4p/++BQ+9vrjueWRjZz3tV+xdrMHvc1s4ilmsmgB5mWtzwU2DlH3Ag50QY1035KaMkV85FUv4rt/+lJ27enn/Kt+xQ8fail1WGZmo6qYyeIBYJGkhZIyJAnhptxKko4HGoF7s4pvB14nqTEd2H5dWjZmnXnsDG79i1dw6twG/vqGlVz2w0fp27uv1GGZmY2KoiWLiOgHLib5kF8D3BARqyRdIem8rKrLgesja4Q4InYAnyZJOA8AV6RlY9oR06r47p+ewYfPPpbrfvscH/7OQ3T37S28o5nZGKeJchXPsmXLorm5udRh7Pfte5/hH368ijOPmcF/XLiMusryUodkZjaIpAcjYlmher6Du0jec+bRXPmOU/ntMzt49zfup72rt9QhmZk9b04WRfTmpXP5t3edxuqNu3jH1+9j667uUodkZva8OFkU2etOPpJr3v97bGjr4m1fv5fW3T2lDsnMbMScLA6Dl79oJt/+wBls3tnNx25c6bu9zWzccbI4TF6yoJG/f9OJ/GJtK9f+5plSh2NmNiJOFofRe166gFefcAT/dOvjrNm0q9ThmJkNm5PFYSSJz791MfU1FfzFdQ/7HgwzGzecLA6zGXWVfOntp7JuawefuWVNqcMxMxsWJ4sSeOWiJj74yoV8+75nuWP1llKHY2ZWkJNFifzt64/n5NnT+PiNK9ni+y/MbIxzsiiRyvIyvrp8Kd19+/jb76/0bHtmNqY5WZTQsU11fOLcE7ln3Tau8eW0ZjaGOVmU2DtPn89rTpzF5257nMc3+3JaMxubnCxKTBKfe8spTKuq4C+vW+HLac1sTHKyGANm1FXyhbctZu2W3Xz+trWlDsfMbBAnizHiVccfwYVnLuCbv36au59oLXU4ZmYHcbIYQy5744ksOqKOv/3+SnZ0ev4LMxs7nCzGkKqKMr58wRLaunr5s28309XbX+qQzMwAJ4sx5+TZ9Vz5jiU8+GwbH7i2mT29HvA2s9JzshiDzl08my+9fQn3Pb2di77d7CukzKzkiposJJ0jaa2k9ZIuHaLO2yWtlrRK0n9nlX9O0mPp8o5ixjkW/dHSOXz+LYu5Z902PvydB+npd8Iws9IpWrKQVAZcBbwBOAlYLumknDqLgMuAl0fEycBfpeVvAk4DlgBnAB+TNK1YsY5Vb1s2j//35lO4a20rH/nuw/T27yt1SGY2SRXzzOJ0YH1EPBURvcD1wPk5dT4IXBURbQARsTUtPwn4ZUT0R0QnsBI4p4ixjlnvPGM+V5x/Mj9bs4UPfquZNl8lZWYlUMxkMQfYkLXekpZlOw44TtKvJd0naSAhrATeIKlG0kzgVcC83DeQdJGkZknNra0T996E9555NP/0x6dw75PbedNX7+Gh59pKHZKZTTLFTBbKU5b7aNVyYBFwNrAc+Iakhoj4KXAr8BvgOuBeYNB1pBFxdUQsi4hlTU1Noxn7mLP89Pnc+OEzKSsTb//3e/nGPU8R4SfVmtnhUcxk0cLBZwNzgY156vw4Ivoi4mlgLUnyICI+ExFLIuK1JIlnXRFjHRcWz23g5o++kj844Qj+7y1ruOjbD7Kzq6/UYZnZJFDMZPEAsEjSQkkZ4ALgppw6PyLpYiLtbjoOeEpSmaQZafliYDHw0yLGOm7UV1fw9fe8hH849yTuenwrr73yl1z32+fo3+vBbzMrnqIli4joBy4GbgfWADdExCpJV0g6L612O7Bd0mrgLuBjEbEdqADuScuvBt6dHs9InlT7gVcs5Acffhnzptdw2Q8f5XVfvpvbHtvkrikzKwpNlA+XZcuWRXNzc6nDOOwigjtWb+Hzt69l/dYOlsxr4OOvP54zj52BlG/YyMzsAEkPRsSygvWcLCaG/r37+MFDLVx5xzo27+rm+FlTeddL5/PmpXOYWlVR6vDMbIxyspikuvv2ctOKjXzn/md5pGUnNZkyzl8ym3edsYCTZ0/z2YaZHcTJwnikpZ3v3PcsN63cSHffPo5pquXcU47iTYtnc9ysOicOM3OysAN2dvXxk0c2cuujm7jvqe3sC3jREXW88ZSjeM2JR/Di2fVMmeLEYTYZOVlYXq27e7ht1WZueWQj9z+9gwiYWZfhrEVN/P7xTZy1qInG2kypwzSzw8TJwgra3tHD3eta+cXaVu5+opW2rj6k5Oa/sxbN5Kzjmlgyr4GKMj/J3myicrKwEdm7L3ikpZ1frG3lnnWtrNjQzr6Auspyzjx2Bi87dgbLFkznxKOmUu7kYTZhOFnYC7JzTx/3PrmNu9dt4551rWzYsQeAmkwZS+c38JIF0zltfgOnzm1wt5XZOOZkYaNqY/semp9t48FndvDAM208vnkX+9JfnXnTq1k8p4FT5tazeE49J8+up77G93aYjQfDTRblhyMYG/9mN1RzXkM15506G4Dd3X08+rudPNKyk0dbdrKypZ1bHt20v/686dW8eHY9L55Tz0lHTWPRrDpm11f7qiuzccrJwp6XqVUVvOzYmbzs2Jn7y3Z09vLo73ayauNOVv1uF49t3Mn/PrZ5//bqijJedETdQctxs6Yyf3oNZU4iZmOau6GsqHZ19/H4pt2s39rBuq3Jzye3drBxZ/f+OpnyKRwzs5ZFs6ZybFMtxzbVcUxTLcfMrKM6U1bC6M0mPndD2ZgwraqC0xdO5/SF0w8q7+jpTxLIloFE0sGKDW3c/MhGsr+/zGmo5uiZNcxrrGHe9BrmT09+zmusZnptxnehmx0mThZWEnWV5SyZ18CSeQ0HlXf37eWZ7Z08ubWTJ1s7eLK1g+d2dPGzNVvY1nHw/OM1mTLmNlbvTyRzG6uZP72G+TOS5FJb6V9vs9HivyYbU6oqyjjhyGmccOS0Qds6e/ppadvDs9s7aWnbw4a2ruTnji7uf3oHHT0HT3kysy7D3MYa5jRUM7uhitkN1cxuqGZOQzVH1Vf5zMRsBJwsbNyorSzn+COncvyRUwdtiwjau/rY0NbFczuSZcOOLjbs2MOaTbv42Zot9PQfPJtgpnwKR06r4sj6Ko6qT34eOa1qf9mR9VU01VX6JkQznCxsgpBEY22GxtoMi+c2DNoeEezo7GVjeze/a9/D5p172LSrm807u9m0s5uHnmtjy84eenOmpy2bImZNreSo9GxkTkM1s6ZV0TS18qBlamW5z1JsQnOysElBEjPqKplRV8kpc+vz1okI2rr62LRzD1t2dbOxPUkmG3fuYVN7N4/+bic/Xb2F3v7B851XVUxh1rQqZk2tYlZ9FbOmVibrWWcrR0yrpKrCV3fZ+ORkYZaSxPTaDNNrM5w8e+iE0t7VR2tHD627Dyxbd3ezZVcPm3d182hLO3fs6qa7b3BSaaypYGZdZbJMrWRmXYaZdZU01VUyvTbDjHR9Rl2Gmoz/PG3s8G+j2Qhkd3cdN2vw2MmAiGBXdz9b0q6uzbu62bKzmy27u9m2u5dtHT082tLOto7eQQPzA6oryvYnj5l1lTRNzTCjNkkkM+oqmVmb/GysraChOkOm3GMrVjxFTRaSzgG+ApQB34iIz+ap83bgciCAlRHxzrT888CbgCnAHcBfxkS5g9AmPEnUV1dQX11xyKQCsKd3L9s7e9je0cuOziSRbO/sZdvunv2vW9q6WLGhnR2dPfufyZWrrrKchpoKGmoqaKzJ0FSXjKckZzHpGUuabBprnFxsZIqWLCSVAVcBrwVagAck3RQRq7PqLAIuA14eEW2SjkjLXwa8HFicVv0V8PvAL4oVr1mpVGfKmJupYW5jTcG6+/YF7Xv62N7Rw7aOXrZ39tDW2UtbVx9tXb20d/XR3pUknadaO2nt6Mk7xgIwrao8OTNJk0tDTYbptRU01GSYWXfgLGbgzMZ3009uxTyzOB1YHxFPAUi6HjgfWJ1V54PAVRHRBhARW9PyAKqADCCgAthSxFjNxoUpUw6MqyyaVbj+QHfYto4etu3uYUdnL9s7e9OzmOSspa2rl007u1mzaRc7unrzjrUAZMqmUFNZRm2mnNrKMmoy5UyrrmBGbXKmMr22gsbaDDNqM0yvrWR6bQXTaytpqK7wAyQngGImiznAhqz1FuCMnDrHAUj6NUlX1eURcVtE3CvpLmATSbL4WkSsyX0DSRcBFwHMnz9/9FtgNs5ld4cd21Q3rH2yu8W2d/YkYyydPezu7qezp5/Onr109fbT0dPPzj19PL2tg7bOviHHXqYIGmsy1FdXMDWNJVnKaajOpF1nGRqqK2isTbZNS+tUlvtsZqwoZrLI91Uit7e1HFgEnA3MBe6R9GJgJnBiWgZwh6SzIuLugw4WcTVwNSQPEhy90M0mr5GLJPedAAAKuklEQVR0i2Xr6d9Le1ff/rGX7Z3pmUxHLzu6etm1p4+d6bJhRxftXb3s3NM35BgMJJck11cnA/j1NRU01iSvG2ormF6TSS+HTs5mZtRVMqM248uTi6SYyaIFmJe1PhfYmKfOfRHRBzwtaS0Hksd9EdEBIOl/gZcCd2NmY1JleRmzppUxa1rVsPfZty/Y3dPPzq4+2vckYy8DCWXXnr79CWXnnj7au/p4ZlsX7XvaaevqG3Ispqpiyv4zmcaazIGzlaoDZyz11QcuBBj4WZMp842Vh1DMZPEAsEjSQuB3wAXAO3Pq/AhYDlwraSZJt9RTwDHAByX9E8kZyu8DXy5irGZWAlOmHOgmm8/wz2Qigq7evWzvSLrItnf0sj29cqy9K0k6A4P9azfvZld30mU2VIKBZExmWto9liSTAwlnRl0yTjQjvRemvjpDXWU5dVXl1FSUTYoxmaIli4jol3QxcDvJeMQ3I2KVpCuA5oi4Kd32Okmrgb3AxyJiu6QbgT8AHiXpurotIn5SrFjNbHyRRG1lObWV5cyfMfwk0923d3932IEryA5cTZbdVbZ1dzdPbNlNW2cvnb17DxEL1KWD/Y3poP70mmSwv7Emk8SZKUvjLaOusoJpaUKqr66gumJ8nNF48iMzswK6+/buH3/Z3tnDru5+Orr76ejpo6O7f39XWltXLzu6+mjrTMZthhr0z1ZRJuqrM8klzLUZpqddZ401GaZVV1BXWc7UqvLkTKayPB27SbrPRuMCAE9+ZGY2SqoqyvY/4n4k+vbuo6t3L509/ekVZHvpSLvEcpf998ds62DHs8l6/6FG/0nmdGmsyXDagkb+ZfnSF9LEgpwszMyKpKJsCvXVyRVdIxURdPftY3d3H7t7kjOZ3Wmiye0+O6p++BcVPF9OFmZmY5AkqjNlVGfKOKLUwZA8d8nMzOyQnCzMzKwgJwszMyvIycLMzApysjAzs4KcLMzMrCAnCzMzK8jJwszMCpowz4aS1Ao8+wIOMRPYNkrhlNpEagtMrPZMpLaA2zOWDbctCyKiqVClCZMsXihJzcN5mNZ4MJHaAhOrPROpLeD2jGWj3RZ3Q5mZWUFOFmZmVpCTxQFXlzqAUTSR2gITqz0TqS3g9oxlo9oWj1mYmVlBPrMwM7OCnCzMzKygSZ8sJJ0jaa2k9ZIuLXU8IyXpm5K2Snosq2y6pDskrUt/NpYyxuGSNE/SXZLWSFol6S/T8vHanipJv5W0Mm3PP6blCyXdn7bne5IypY51uCSVSXpY0s3p+nhuyzOSHpW0QlJzWjYuf9cAJDVIulHS4+nf0Jmj2Z5JnSwklQFXAW8ATgKWSzqptFGN2LXAOTlllwJ3RsQi4M50fTzoB/4mIk4EXgp8JP3/GK/t6QH+ICJOBZYA50h6KfA54Mq0PW3AB0oY40j9JbAma308twXgVRGxJOt+hPH6uwbwFeC2iDgBOJXk/2n02hMRk3YBzgRuz1q/DLis1HE9j3YcDTyWtb4WOCp9fRSwttQxPs92/Rh47URoD1ADPAScQXJXbXlaftDv4FhegLnpB84fADcDGq9tSeN9BpiZUzYuf9eAacDTpBctFaM9k/rMApgDbMhab0nLxrtZEbEJIP05FqbwHRFJRwNLgfsZx+1Ju21WAFuBO4AngfaI6E+rjKffuS8DHwf2peszGL9tAQjgp5IelHRRWjZef9eOAVqBa9Juwm9IqmUU2zPZk4XylPla4hKTVAf8APiriNhV6nheiIjYGxFLSL6Vnw6cmK/a4Y1q5CSdC2yNiAezi/NUHfNtyfLyiDiNpBv6I5LOKnVAL0A5cBrwbxGxFOhklLvQJnuyaAHmZa3PBTaWKJbRtEXSUQDpz60ljmfYJFWQJIrvRsQP0+Jx254BEdEO/IJkLKZBUnm6abz8zr0cOE/SM8D1JF1RX2Z8tgWAiNiY/twK/A9JMh+vv2stQEtE3J+u30iSPEatPZM9WTwALEqv6MgAFwA3lTim0XATcGH6+kKSvv8xT5KA/wTWRMSXsjaN1/Y0SWpIX1cDryEZdLwLeGtabVy0JyIui4i5EXE0yd/JzyPiXYzDtgBIqpU0deA18DrgMcbp71pEbAY2SDo+LXo1sJrRbE+pB2ZKvQBvBJ4g6Uv++1LH8zzivw7YBPSRfLv4AElf8p3AuvTn9FLHOcy2vIKkG+MRYEW6vHEct2cx8HDanseAT6blxwC/BdYD3wcqSx3rCNt1NnDzeG5LGvfKdFk18Lc/Xn/X0tiXAM3p79uPgMbRbI8f92FmZgVN9m4oMzMbBicLMzMryMnCzMwKcrIwM7OCnCzMzKwgJwsb8yT9Jv15tKR3jvKx/y7fexWLpD+S9MkiHfvvCtca8TFPkXTtaB/Xxh9fOmvjhqSzgb+NiHNHsE9ZROw9xPaOiKgbjfiGGc9vgPMiYtsLPM6gdhWrLZJ+BvxJRDw32se28cNnFjbmSepIX34WeGU6/8Al6UP6viDpAUmPSPqztP7Z6bwY/w08mpb9KH1g3KqBh8ZJ+ixQnR7vu9nvpcQXJD2Wznnwjqxj/yJr3oDvpneeI+mzklansfxznnYcB/QMJApJ10r6d0n3SHoiff7SwMMHh9WurGPna8u7lcynsULS19NH8iOpQ9JnlMyzcZ+kWWn529L2rpR0d9bhf0Jy17ZNZqW+69CLl0IL0JH+PJv0zuF0/SLgE+nrSpK7Vxem9TqBhVl1p6c/q0nupp6Rfew87/UWkqfElgGzgOdIHvF8NrCT5DlIU4B7Se48n07yOOiBs/WGPO14P/DFrPVrgdvS4ywiuQO/aiTtyhd7+vpEkg/5inT9X4H3pq8D+MP09eez3utRYE5u/CTPhfpJqX8PvJR2GXgAmNl49DpgsaSBZxPVk3zo9gK/jYins+r+haQ3p6/npfW2H+LYrwCui6SrZ4ukXwK/B+xKj90CkD5+/GjgPqAb+IakW0jme8h1FMljpLPdEBH7gHWSngJOGGG7hvJq4CXAA+mJTzUHHiLXmxXfgyRzhgD8GrhW0g3ADw8ciq3A7GG8p01gThY2ngn4aETcflBhMrbRmbP+GuDMiOiS9AuSb/CFjj2UnqzXe0km/+mXdDrJh/QFwMUkT2bNtofkgz9b7qBhMMx2FSDgvyLisjzb+iJi4H33kn4ORMSHJJ0BvAlYIWlJRGwn+bfaM8z3tQnKYxY2nuwGpmat3w58OH2sOZKOS58gmqseaEsTxQkkjwkf0Dewf467gXek4wdNwFkkD8zLS8kcHPURcSvwVyQPdcu1BnhRTtnbJE2RdCzJw+3WjqBdubLbcifwVklHpMeYLmnBoXaWdGxE3B8RnySZAW/g8f3HkXTd2STmMwsbTx4B+iWtJOnv/wpJF9BD6SBzK/BHefa7DfiQpEdIPozvy9p2NfCIpIcieeT2gP8hmSZ0Jcm3/Y9HxOY02eQzFfixpCqSb/WX5KlzN/BFScr6Zr8W+CXJuMiHIqJb0jeG2a5cB7VF0idIZoKbQvJU4o8Azx5i/y9IWpTGf2fadoBXAbcM4/1tAvOls2aHkaSvkAwW/yy9f+HmiLixxGENSVIlSTJ7RRyYPtUmIXdDmR1e/w+oKXUQIzAfuNSJwnxmYWZmBfnMwszMCnKyMDOzgpwszMysICcLMzMryMnCzMwK+v/NTscnKHznDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.71392477\n",
      "Test Accuracy: 0.71514976\n"
     ]
    }
   ],
   "source": [
    "parameters_DNN_07 = model(X_train_07, Y_train_07, X_test_07, Y_test_07, learning_rate = 0.0001,\n",
    "          num_epochs = 300, minibatch_size = 512, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.770820\n",
      "1  1000020_8192_20160513  0.503599\n",
      "2  1000065_1455_20160527  0.202747\n",
      "3  1000085_8067_20160513  0.153011\n",
      "4  1000086_2418_20160613  0.189732\n"
     ]
    }
   ],
   "source": [
    "dnn_pred_07 = predict_new(test_dnn, parameters_DNN_07)\n",
    "dnn_pred_07 = dnn_pred_07.transpose()\n",
    "\n",
    "output_07 = output.copy()\n",
    "output_07['pred_prob'] = dnn_pred_07\n",
    "out_07 = output_07.groupby(\"uid\", as_index=False).mean()\n",
    "out_07 = out_07[[\"uid\", \"pred_prob\"]]\n",
    "out_07.columns = [\"uid\", \"label\"]\n",
    "print(out_07.head())\n",
    "out_07.to_csv('DNN_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = pd.read_csv('try.csv')\n",
    "blend = SGD.copy()\n",
    "\n",
    "blend['label'] = out_07['label']*0.5 + blend['label']*0.5\n",
    "\n",
    "blend.to_csv('try.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
