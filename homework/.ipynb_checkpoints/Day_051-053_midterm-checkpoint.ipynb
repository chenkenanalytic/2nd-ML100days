{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>376492</td>\n",
       "      <td>1041</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160127.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160215.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>11197.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160114.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2881376</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160321.0</td>\n",
       "      <td>20160329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0   1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1   1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2   1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3   1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4   2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5   2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6     73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7    163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8   3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9     94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "10   253750         8390        NaN           NaN       0.0            NaN   \n",
       "11   253750         8390     7531.0          20:5       0.0     20160327.0   \n",
       "12   376492         1041    13490.0          30:5       2.0     20160127.0   \n",
       "13  1964720         7884        NaN           NaN      10.0            NaN   \n",
       "14  1964720         7884     6704.0          20:1      10.0     20160215.0   \n",
       "15  1113008         1041        NaN           NaN       2.0            NaN   \n",
       "16  1113008         1041    11197.0          30:5       2.0     20160114.0   \n",
       "17  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "18  2881376         8390     7531.0          20:5       0.0     20160321.0   \n",
       "19  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "\n",
       "          Date  \n",
       "0   20160217.0  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10  20160327.0  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13  20160115.0  \n",
       "14         NaN  \n",
       "15  20160114.0  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18  20160329.0  \n",
       "19         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfoff = pd.read_csv('data/ml100marathon-02-01/train_offline.csv')\n",
    "dftest = pd.read_csv('data/ml100marathon-02-01/test_offline.csv')\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=True)\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "dfoff.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    710665\n",
       "-1    413773\n",
       " 1     36304\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creat target label \n",
    "\"\"\"\n",
    "According to the definition, \n",
    "1) buy with coupon within (include) 15 days ==> 1\n",
    "2) buy with coupon but out of 15 days ==> 0\n",
    "3) buy without coupon ==> -1 (we don't care)\n",
    "\"\"\"\n",
    "def label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "dfoff[\"label\"] = dfoff.apply(label, axis=1)\n",
    "dfoff[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - weekday acquired coupon\n",
    "def getWeekday(row):\n",
    "    if (np.isnan(row)) or (row==-1):\n",
    "        return row\n",
    "    else:\n",
    "        return pd.to_datetime(row, format = \"%Y%m%d\").dayofweek+1 # add one to make it from 0~6 -> 1~7\n",
    "\n",
    "dfoff['weekday'] = dfoff['Date_received'].apply(getWeekday)\n",
    "dftest['weekday'] = dftest['Date_received'].apply(getWeekday)\n",
    "\n",
    "# weekday_type (weekend = 1)\n",
    "dfoff['weekday_type'] = dfoff['weekday'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 ) # apply to trainset\n",
    "dftest['weekday_type'] = dftest['weekday'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 ) # apply to testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "weekdaycols = ['weekday_' + str(i) for i in range(1,8)]\n",
    "print(weekdaycols)\n",
    "\n",
    "tmpdf = pd.get_dummies(dfoff['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dfoff[weekdaycols] = tmpdf\n",
    "\n",
    "tmpdf = pd.get_dummies(dftest['weekday'].replace(-1, np.nan))\n",
    "tmpdf.columns = weekdaycols\n",
    "dftest[weekdaycols] = tmpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features - coupon discount and distance\n",
    "def getDiscountType(row):\n",
    "    if row == 'null':\n",
    "        return 'null'\n",
    "    elif ':' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertRate(row):\n",
    "    \"\"\"Convert discount to rate\"\"\"\n",
    "    if row == 'null':\n",
    "        return 1.0\n",
    "    elif ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return 1.0 - float(rows[1])/float(rows[0])\n",
    "    else:\n",
    "        return float(row)\n",
    "\n",
    "def getDiscountMan(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def getDiscountJian(row):\n",
    "    if ':' in row:\n",
    "        rows = row.split(':')\n",
    "        return int(rows[1])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def processData(df):\n",
    "    \n",
    "    # convert discunt_rate\n",
    "    df['discount_rate'] = df['Discount_rate'].astype('str').apply(convertRate)\n",
    "    df['discount_man'] = df['Discount_rate'].astype('str').apply(getDiscountMan)\n",
    "    df['discount_jian'] = df['Discount_rate'].astype('str').apply(getDiscountJian)\n",
    "    df['discount_type'] = df['Discount_rate'].astype('str').apply(getDiscountType)\n",
    "    \n",
    "    # convert distance\n",
    "    df.loc[df.Distance.isna(), \"Distance\"] = 99\n",
    "    return df\n",
    "\n",
    "dfoff = processData(dfoff)\n",
    "dftest = processData(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 667753, #positive: 32472\n",
      "Valid size: 79216, #positive: 3832\n"
     ]
    }
   ],
   "source": [
    "## Naive model\n",
    "def split_train_valid(row, date_cut=\"20160416\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "    \n",
    "df = dfoff[dfoff['label'] != -1].copy()\n",
    "df[\"is_train\"] = df[\"Date_received\"].apply(split_train_valid)\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "original_feature = ['discount_rate',\n",
    "                    'discount_type',\n",
    "                    'discount_man', \n",
    "                    'discount_jian',\n",
    "                    'Distance', \n",
    "                    'weekday', \n",
    "                    'weekday_type'] + weekdaycols\n",
    "print(len(original_feature),original_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['discount_rate', 'discount_type', 'discount_man', 'discount_jian', 'Distance', 'weekday', 'weekday_type', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', 'weekday_7']\n"
     ]
    }
   ],
   "source": [
    "predictors = original_feature\n",
    "print(predictors)\n",
    "\n",
    "def check_model(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__alpha': [ 0.001, 0.01, 0.1],\n",
    "        'en__l1_ratio': [ 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  2.6min finished\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = check_model(train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = model.predict_proba(valid[predictors])\n",
    "valid1 = valid.copy()\n",
    "valid1['pred_prob'] = y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.743, Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 19)\n",
      "(306313, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()\n",
    "\n",
    "y_test_pred = model.predict_proba(testset[predictors])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.114271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.087881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.067419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.070343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.114271\n",
       "1  1000020_8192_20160513  0.087881\n",
       "2  1000065_1455_20160527  0.067419\n",
       "3  1000085_8067_20160513  0.070343\n",
       "4  1000086_2418_20160613  0.061017"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "# out.to_csv(\"baseline_example.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.to_csv('baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized - Midterm Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  2.8min finished\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-cd69c4fdbdac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mout_01\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mout_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred_01\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mout_01\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3629\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3630\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "## method 1 -> try to train all the data in replace of the validation part\n",
    "\n",
    "model_01 = check_model(df, predictors)\n",
    "\n",
    "y_pred_01 = model_01.predict_proba(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.116712\n",
      "1  1000020_8192_20160513  0.088354\n",
      "2  1000065_1455_20160527  0.070453\n",
      "3  1000085_8067_20160513  0.071660\n",
      "4  1000086_2418_20160613  0.062500\n"
     ]
    }
   ],
   "source": [
    "output_01 = output.copy()\n",
    "output_01['pred_prob'] = y_pred_01[:, 1]\n",
    "out_01 = output_01.groupby(\"uid\", as_index=False).sum()\n",
    "out_01 = out_01[[\"uid\", \"pred_prob\"]]\n",
    "out_01.columns = [\"uid\", \"label\"]\n",
    "print(out_01.head())\n",
    "out_01.to_csv('all_data_training.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   53.4s finished\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## method 2 -> modify model - change scaler + logistic regression\n",
    "\n",
    "def check_model_02(data, predictors):\n",
    "    \n",
    "    classifier = lambda: LogisticRegression(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', MinMaxScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__C': [ 0.001, 0.01, 0.1, 1.0 ],\n",
    "        'en__tol': [ 0.0001, 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search\n",
    "\n",
    "model_02 = check_model_02(df, predictors)\n",
    "\n",
    "y_pred_02 = model_02.predict_proba(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.092916\n",
      "1  1000020_8192_20160513  0.075217\n",
      "2  1000065_1455_20160527  0.055945\n",
      "3  1000085_8067_20160513  0.063955\n",
      "4  1000086_2418_20160613  0.059056\n"
     ]
    }
   ],
   "source": [
    "output_02 = output.copy()\n",
    "output_02['pred_prob'] = y_pred_02[:, 1]\n",
    "out_02 = output_02.groupby(\"uid\", as_index=False).mean()\n",
    "out_02 = out_02[[\"uid\", \"pred_prob\"]]\n",
    "out_02.columns = [\"uid\", \"label\"]\n",
    "print(out_02.head())\n",
    "out_02.to_csv('MM_scaler.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 3 -> try\n",
    "\n",
    "out_03 = out_01.copy()\n",
    "\n",
    "out_03['label'] = out_03['label']*3\n",
    "\n",
    "out_03.to_csv('try.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 4 -> issues: sample data bias \n",
    "\n",
    "df_04 = df[df['label'] == 1].append(df[df['label'] == 0].head(60000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   20.9s finished\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "model_04 = check_model(df_04, predictors)\n",
    "\n",
    "y_pred_04 = model_04.predict_proba(testset[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid     label\n",
      "0  1000020_2705_20160519  0.617518\n",
      "1  1000020_8192_20160513  0.548521\n",
      "2  1000065_1455_20160527  0.479919\n",
      "3  1000085_8067_20160513  0.488864\n",
      "4  1000086_2418_20160613  0.424386\n"
     ]
    }
   ],
   "source": [
    "output_04 = output.copy()\n",
    "output_04['pred_prob'] = y_pred_04[:, 1]\n",
    "out_04 = output_04.groupby(\"uid\", as_index=False).mean()\n",
    "out_04 = out_04[[\"uid\", \"pred_prob\"]]\n",
    "out_04.columns = [\"uid\", \"label\"]\n",
    "print(out_04.head())\n",
    "out_04.to_csv('unbias_training_set.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## method 5 -> issues: sample data bias . try\n",
    "\n",
    "out_05 = out_04.copy()\n",
    "\n",
    "out_05['label'][out_05['label']>=0.5] = 1\n",
    "out_05['label'][out_05['label']<0.5] = 0\n",
    "\n",
    "out_05.to_csv('unbias_training_set_binary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 6 -> deep learning\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import random_mini_batches  ### 參考使用 Coursera 吳恩達老師上課教材\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y,None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 TensorFlow 模型(幾層神經網路) 及 初始化神經元參數\n",
    "def initialize_parameters():\n",
    "    \n",
    "    # 設定 random seeds → 避免每次訓練結果都不一樣\n",
    "    tf.set_random_seed(1)                   \n",
    "    \n",
    "    # 設共三層神經\n",
    "    W1 = tf.get_variable(\"W1\", [8,14], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [8,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [4,8], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [4,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,4], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 TensorFlow 向前傳播 計算公式\n",
    "def forward_propagation(X, parameters):\n",
    "    ### LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> Sigmoid\n",
    "    \n",
    "    # 抓取神經元權重參數 (parameters)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "   \n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                  # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                 # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算模型的 成本 (Cost) → 模型的好壞\n",
    "\n",
    "def class_balanced_sigmoid_cross_entropy(logits, label, name='cross_entropy_loss'):\n",
    "    y = tf.cast(label, tf.float32)\n",
    "    count_neg = tf.reduce_sum(1. - y) # the number of 0 in y\n",
    "    count_pos = tf.reduce_sum(y) # the number of 1 in y (less than count_neg)\n",
    "    beta = count_neg / (count_neg + count_pos)\n",
    "    pos_weight = beta / (1 - beta)\n",
    "    cost = tf.nn.weighted_cross_entropy_with_logits(logits, y, pos_weight)\n",
    "    cost = tf.reduce_mean(cost * (1 - beta), name=name)\n",
    "    return cost\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    Z3 = tf.sigmoid(Z3)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = class_balanced_sigmoid_cross_entropy(logits = logits, label = labels)\n",
    "#     cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合全部函數，建立機器學習模型\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 200, minibatch_size = 1024, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             \n",
    "    seed = 3                                          \n",
    "    (n_x, m) = X_train.shape                          \n",
    "    n_y = Y_train.shape[0]                            \n",
    "    costs = []                                        \n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # 初始化神經元權重參數\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # 向前傳播\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # 成本函數 → 計算成本\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # 反向傳播 (設定最佳化計算函數→最小化成本) \n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # 初始化全部變數\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # 啟動 TensorFlow \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        # 反覆訓練\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            epoch_cost = 0.                       \n",
    "            num_minibatches = int(m / minibatch_size) \n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "  \n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print 每 100 次訓練的成本\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # 視覺化 cost 變化\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # 儲存最後訓練出來的模型參數\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # 計算模型預測的能力\n",
    "        correct_prediction = tf.equal(tf.round(tf.nn.sigmoid(Z3)), Y)\n",
    "\n",
    "        # 計算模型對於測試集的準確率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# df[predictors]\n",
    "mm = MinMaxScaler()\n",
    "mm_target = ['discount_man','discount_jian','Distance','weekday']\n",
    "\n",
    "df_dnn = df[predictors].copy()\n",
    "Y = df['label'].copy()\n",
    "\n",
    "df_dnn[mm_target] = mm.fit_transform(df_dnn[mm_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14, 522878)\n",
      "Y_train shape: (1, 522878)\n",
      "X_test shape: (14, 224091)\n",
      "Y_test shape: (1, 224091)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df_dnn, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = X_train.transpose().values\n",
    "X_test = X_test.transpose().values\n",
    "Y_train = Y_train.values.reshape(1,len(Y_train))\n",
    "Y_test = Y_test.values.reshape(1,len(Y_test))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.223676\n",
      "Cost after epoch 100: 0.221669\n",
      "Cost after epoch 200: 0.219673\n",
      "Cost after epoch 300: 0.217675\n",
      "Cost after epoch 400: 0.215661\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VHXaxvHvk0BooUuTrqAISDOACAQLzbJgAcUCFlhsrEB219XVd3V1d3Vll2JBwN4VsCFK1yUUQQLSkaoIglIUBEHq8/4xJzqbTUggGSaZ3J/rysXM7/zOmecwMHfOnJnnmLsjIiJyouKiXYCIiBRsChIREckVBYmIiOSKgkRERHJFQSIiIrmiIBERkVxRkEihZWaTzOzGaNchUtApSOSkM7OvzKxjtOtw94vd/aVo1wFgZv8xs34n4XGKmdnzZvajmX1rZinZzB8czNsdrFcsbFkdM/vEzPaZ2RcZn9Ns1n3YzJaZ2WEzezDPd1ROKgWJxCQzKxLtGtLlp1qAB4H6QG3gAuBuM+ua2UQz6wLcA1wE1AFOA/4aNuUN4HOgInAfMN7MKuVw3XXA3cCHebJXElUKEslXzOwyM1tsZrvMbK6ZNQlbdo+ZrTezPWa20syuCFt2k5nNMbNhZvY98GAwNtvM/mVmP5jZl2Z2cdg6vxwF5GBuXTNLDR57upk9ZWavZrEP55vZZjP7k5l9C7xgZuXNbKKZbQ+2P9HMagTz/w60B540s71m9mQw3sDMppnZ92a22syuzoO/4j7Aw+7+g7uvAp4Bbspi7o3Ac+6+wt1/AB5On2tmZwAtgAfcfb+7vw0sA67Kbl0Ad3/J3ScBe/JgnyTKFCSSb5hZC+B54FZCv+WOBiaEvSWyntALbllCv92+ambVwjbRGtgAVAb+Hja2GjgFeAx4zswsixKONfd14LOgrgeB3tnsTlWgAqHf/PsT+r/2QnC/FrAfeBLA3e8DZgED3D3R3QeYWSlgWvC4lYFrgZFm1iizBzOzkUH4ZvazNJhTHjgVWBK26hIg020G4xnnVjGzisGyDe6+J8PyRjlYV2KMgkTyk98Co919vrsfCc5fHADOBXD3ce6+xd2PuvtbwFqgVdj6W9z9CXc/7O77g7GN7v6Mux8BXgKqAVWyePxM55pZLaAl8Bd3P+jus4EJ2ezLUUK/rR8IfmPf6e5vu/u+4MX370CHY6x/GfCVu78Q7M8i4G2gR2aT3f0Ody+XxU/6UV1i8OfusFV3A6WzqCExk7kE8zMuy7itY60rMUZBIvlJbeD34b9NAzUJ/RaNmfUJe9trF9CY0NFDuk2ZbPPb9Bvuvi+4mZjJvGPNPRX4Pmwsq8cKt93df06/Y2YlzWy0mW00sx+BVKCcmcVnsX5toHWGv4vrCR3pnKi9wZ9lwsbKkPXbS3szmUswP+OyjNs61roSYxQkkp9sAv6e4bfpku7+hpnVJvR+/gCgoruXA5YD4W9TRaqV9VaggpmVDBurmc06GWv5PXAm0NrdywDJwbhlMX8TMDPD30Wiu9+e2YOZ2ajg/EpmPysAgnMVW4GmYas2BVZksQ8rMpn7nbvvDJadZmalMyxfkYN1JcYoSCRaippZ8bCfIoSC4jYza20hpczs0uDFqhShF9vtAGZ2M6Ejkohz941AGqET+Alm1gb4zXFupjSh8yK7zKwC8ECG5d8R+mRTuonAGWbW28yKBj8tzeysLGq8LQiazH7Cz4G8DNwfnPxvQOjtxBezqPlloK+ZNQzOr9yfPtfd1wCLgQeC5+8KoAmht9+OuS5AsD/FCb0GFQm2kdXRmeRzChKJlo8IvbCm/zzo7mmEXtieBH4g9BHRmwDcfSXwb+BTQi+6ZwNzTmK91wNtgJ3A34C3CJ2/yanhQAlgBzAPmJxh+QigR/CJrseD8yidgV7AFkJvu/0TKEbuPEDoQwsbgZnAEHefDGBmtYIjmFoAwfhjwCfB/I38dwD2ApIIPVePAj3cfXsO132G0PN+LaGPDu8n+w8wSD5lurCVyPEzs7eAL9w945GFSKGjIxKRHAjeVjrdzOIs9AW+7sB70a5LJD/IT9+4FcnPqgLvEPoeyWbgdnf/PLolieQPemtLRERyRW9tiYhIrhSKt7ZOOeUUr1OnTrTLEBEpUBYuXLjD3StlNy+iQRKclBwBxAPPuvujGZanAP2Aw4S+H3CLu280s2bA04S+DXuE0JfU3sqw7hPAze6e1beUf1GnTh3S0tLyYpdERAoNM9uYk3kRe2sr+HLRU8DFQEPgWjNrmGHa50BS0AtoPKHPnQPsA/oEX6TqCgw3s3Jh204CyiEiIlEXyXMkrYB17r7B3Q8CbxL6yOQv3P2TsP5F84Aawfgad18b3N4CbAPSr3MQDwwhdC0DERGJskgGSXX+u7Hd5mAsK32BSRkHzawVkEDo27gQ6rU0wd23HuvBzay/maWZWdr27duPq3AREcm5SJ4jyeyaD5l+1tjMbiDUaqFDhvFqwCvAje5+1MxOBXoC52f34O4+BhgDkJSUpM84i4hESCSDZDP/3SG1BqGeQf/FQtd5vg/o4O4HwsbLELoM5/3uPi8Ybg7UA9YF1xsqaWbr3L1eZHZBRESyE8kgWQDUN7O6wDeEGrxdFz7BzJoTugpeV3ffFjaeALwLvOzu49LH3f1Dwq7HYGZ7FSIiItEVsXMk7n6Y0PmMKcAqYKy7rzCzh8ysWzBtCKELB40LLliUftW5qwldr+GmYHxx8JFgERHJZwpFi5SkpCQ/ke+RTFy6hcNHnO7NTiXry3yLiMQmM1vo7knZzVOLlGN4e+FmBr21mL4vpbFl1/7sVxARKYQUJMfw7I0t+b/LGvLp+p10HpbKa/M3cvRo7B/BiYgcDwXJMcTHGX3b1WXKoGSa1CjLfe8u5/pn57Nx50/RLk1EJN9QkORArYolea1fax658myWf7ObLsNTeXbWBo7o6EREREGSU2bGta1qMTUlmbann8LfPlxFj1FzWfvdnmiXJiISVQqS41StbAmevTGJEb2a8dWOn7j08dk8PmMth44cjXZpIiJRoSA5AWZG92bVmZ7SgS6NqzJ02hp+88Rslm3eHe3SREROOgVJLlRMLMYT1zbnmT5JfP/TQS4fOYdHJ33Bz4eORLs0EZGTRkGSBzo1rMK0lA70aFGDUTPXc8mIWSz46vtolyUiclIoSPJI2RJF+WePJrzStxUHDh/l6tGf8sD7y/npwOFolyYiElEKkjzWvn4lpg5O5sY2dXh53kY6D0sldY2uhyIisUtBEgGlihXhwW6NGHdrG4oVjaPP85/xh3FL2LXvYLRLExHJcwqSCEqqU4GP7mrPnReczruff0OnYalMXn7MCzuKiBQ4CpIIK140nj92acCEAW2pXLoYt726iNtfXci2PT9HuzQRkTyhIDlJGp1alvfubMvdXc9kxhfb6DQ0lfELN1MY2viLSGxTkJxERePjuOP8ekwa2J76lRP5w7gl3PTCAr5Ri3oRKcAUJFFweqVExt7ahr92a8SCr76n89CZvPLpV2pRLyIFkoIkSuLijBvPq8OUQcm0qF2e/3t/Bb3GzGPD9r3RLk1E5LgoSKKsZoWSvHxLK/7Vsymrv9tD1xGzGDVzPYfVBFJECggFST5gZvQ4pwbTUpK58MzKPDrpC64YOZdVW3+MdmkiItlSkOQjlUsXZ1Tvcxh5fQu27t7Pb56Yzb+nrubAYTWBFJH8S0GSD11ydjWmDe5At2an8sTH67j08dks3PhDtMsSEcmUgiSfKl8qgaFXN+PFm1uy/+AReoyay18/WMG+g2oCKSL5i4Iknzv/zMpMGZxM73Nr88Kcr+g8LJU563ZEuywRkV8oSAqAxGJFeKh7Y8be2oai8XFc/+x8/jR+Kbv3H4p2aSIiCpKCpFXdCkwa2J7bzz+d8Ys202noTKas+DbaZYlIIacgKWCKF43nT10b8N4dbamYWIxbX1nIna8vYsfeA9EuTUQKKQVJAXV2jbJMGNCWP3Q+g2krvqPT0Jm89/k3agIpIiedgqQAKxofx4AL6/PhXe2oc0opBr21mL4vpbFFTSBF5CRSkMSA+lVKM/628/jLZQ35dP1OOg9L5dV5G9UEUkROiogGiZl1NbPVZrbOzO7JZHmKma00s6VmNsPMagfjzczsUzNbESy7Jmyd14JtLjez582saCT3oaCIjzNuaVeXKYOSaVqzLPe/t5xrn5nHlzt+inZpIhLjIhYkZhYPPAVcDDQErjWzhhmmfQ4kuXsTYDzwWDC+D+jj7o2ArsBwMysXLHsNaACcDZQA+kVqHwqiWhVL8mrf1jx2VRNWbv2RrsNTGa0mkCISQZE8ImkFrHP3De5+EHgT6B4+wd0/cfd9wd15QI1gfI27rw1ubwG2AZWC+x95APgsfR35lZlxdcuaTE/pQPIZlXhk0hdc+bSaQIpIZEQySKoDm8Lubw7GstIXmJRx0MxaAQnA+gzjRYHewORcVxqjqpQpzpje5/DUdS3YsivUBHLotDVqAikieSqSQWKZjGV69tfMbgCSgCEZxqsBrwA3u3vG92ZGAqnuPiuLbfY3szQzS9u+fftxFx8rzIxLm4SaQP6m6ak8PmMtlz0+m0VfqwmkiOSNSAbJZqBm2P0awJaMk8ysI3Af0M3dD4SNlwE+BO5393kZ1nmA0FtdKVk9uLuPcfckd0+qVKlSrnYkFpQvlcCwa5rxwk0t+enAYa56ei4PfbBSTSBFJNciGSQLgPpmVtfMEoBewITwCWbWHBhNKES2hY0nAO8CL7v7uAzr9AO6ANdmcpQi2bigQWWmpnTghta1eX7Ol3QelsrstWoCKSInLmJB4u6HgQHAFGAVMNbdV5jZQ2bWLZg2BEgExpnZYjNLD5qrgWTgpmB8sZk1C5aNAqoAnwbjf4nUPsSqxGJFePjyUBPIhPg4bnhuPn8ct4Td+9QEUkSOnxWGlhpJSUmelpYW7TLypZ8PHeHxGWsZnbqBCqUSeLh7Y7o2rhrtskQkHzCzhe6elN08fbO9kCteNJ67uzbg/TvbUimxGLe9upA7X1vE9j1qAikiOaMgEQAaVy/L+wPa8scuZzJt5Xd0HDqTtxduVhNIEcmWgkR+UTQ+jjsvqMdHA9tRv3Iivx+3hD7Pf8am7/dlv7KIFFoKEvkf9SqXZuytbXioeyMWbfyBLsNTeXHOlxxRE0gRyYSCRDIVF2f0aVOHqSkdaFmnAg9+sJKeo+aybtueaJcmIvmMgkSOqXq5Erx4c0uGXdOUDTt+4pIRs3ny47UcUhNIEQkoSCRbZsYVzWswPaUDnRtV4V9T1/CbJ2azbPPuaJcmIvmAgkRy7JTEYjx5XQvG9D6H7386SPenZvPIpFX8fEhNIEUKMwWJHLfOjaoyLaUD17SsyeiZG+g6PJV5G3ZGuywRiRIFiZyQsiWK8siVTXi9X2uOOvQaM4/73l3Gnp/VZkWksFGQSK6cV+8UJg9qT792dXnjs6/pPCyVj7/4LtplichJpCCRXCuZUIT7L2vI27efR+niRbjlxTQGvvk5O/eqzYpIYaAgkTzTvFZ5Jv6uPYM61uejZVvpNCyV9xd/ozYrIjFOQSJ5KqFIHIM6nsGHd7WnVoWSDHxzMf1eSmPr7v3RLk1EIkRBIhFxRpXSvH37efzfZQ2Zu34nnYam8uq8jRxVmxWRmKMgkYiJjzP6tqvLlEHJNK1ZlvvfW06vZ+bx5Y6fol2aiOQhBYlEXK2KJXm1b2seu6oJq7b+SNfhqYyauZ7DarMiEhMUJHJSmBlXt6zJ9JQOnH9mJR6d9AWXj5zDii1qsyJS0ClI5KSqUqY4o3sn8fT1Lfh29wG6PTmHf07+Qm1WRAowBYlExcVnV2N6SjJXNq/O0/9ZzyUjZrHgq++jXZaInAAFiURNuZIJDOnZlFf7tubgkaP0HPUpf3l/OXsPHI52aSJyHBQkEnXt6p/ClEHJ3Ny2Dq/M20jnoTP5ZPW2aJclIjmkIJF8oVSxIjzwm0aMv+08ShYrws0vLGDwW4v5/qeD0S5NRLKhIJF85Zza5fnwrnbcdVF9PliyhY5DZ6rNikg+pyCRfKdYkXhSOp3BxLvaUTNos9L3pTS27FKbFZH8SEEi+VaDqmV45/bzuP/Ss/h0/U46D0vlFbVZEcl3FCSSr8XHGf3an8aUQck0q1mO/3tvOb3GzGP99r3RLk1EAgoSKRBqVSzJK31b8ViPJnzx7Y9cPGIWT32yjkNqsyISdQoSKTDMjKuTajL99x3oeFZlhkxZTfcn57Bss9qsiESTgkQKnMqlizPy+nMYdcM57Nh7gMtHzuGRj1ax/6DarIhEg4JECqyujasyLaUDPc+pwejUDXQdkcqn63dGuyyRQieiQWJmXc1stZmtM7N7MlmeYmYrzWypmc0ws9rBeDMz+9TMVgTLrglbp66ZzTeztWb2lpklRHIfJH8rW6Ioj17VhNf7tcYdrn1mHve+s5Td+w9FuzSRQiNiQWJm8cBTwMVAQ+BaM2uYYdrnQJK7NwHGA48F4/uAPu7eCOgKDDezcsGyfwLD3L0+8APQN1L7IAXHefVCbVZ+274uby3YRKehM5m64ttolyVSKETyiKQVsM7dN7j7QeBNoHv4BHf/xN33BXfnATWC8TXuvja4vQXYBlQyMwMuJBQ6AC8Bl0dwH6QAKZEQz32XNuTdO9pSoVQC/V9ZyB2vLWTbnp+jXZpITItkkFQHNoXd3xyMZaUvMCnjoJm1AhKA9UBFYJe7p7eHzW6bUgg1rVmOD37Xjj90PoPpK7fRaWgq49I2qc2KSIREMkgsk7FM/yeb2Q1AEjAkw3g14BXgZnc/epzb7G9maWaWtn379uMqXAq+ovFxDLiwPh8NbE/9yon8cfxS+jz/GZu+35f9yiJyXCIZJJuBmmH3awBbMk4ys47AfUA3dz8QNl4G+BC4393nBcM7gHJmVuRY2wRw9zHunuTuSZUqVcr1zkjBVK9yImNvbcPD3RuxaOMPdB6WynOzv+SI2qyI5JlIBskCoH7wKasEoBcwIXyCmTUHRhMKkW1h4wnAu8DL7j4ufdxD7018AvQIhm4E3o/gPkgMiIszerepw9SUDrQ+rQIPT1xJj1FzWfvdnmiXJhITIhYkwXmMAcAUYBUw1t1XmNlDZtYtmDYESATGmdliM0sPmquBZOCmYHyxmTULlv0JSDGzdYTOmTwXqX2Q2FK9XAleuKklw65pylc7fuKSx2cxYvpaDh5WmxWR3LDCcAIyKSnJ09LSol2G5CM79h7gwQkrmLh0K2dWKc0/ezShWc1y2a8oUoiY2UJ3T8punr7ZLoXSKYnFePK6FjzbJ4nd+w9x5cg5/G3iSvYd1PXiRY6XgkQKtY4NqzA1JZlerWrx7Owv6Tp8FnPX7Yh2WSIFioJECr0yxYvyjyvO5s3+5xJncN2z8/nTeLVZEckpBYlI4NzTKjJ5UDK3djiN8Ys202noTCYvV5sVkewoSETCFC8az70Xn8X7d7bllMRi3PbqQm5/VW1WRI5FQSKSicbVy/L+gLb8scuZzPhCbVZEjkVBIpKFovFx3HlBPSYNbM8ZVdRmRSQrChKRbJxeKZG3+rfh4csb/9Jm5YU5arMikk5BIpIDcXFG73Nr/9Jm5a8frKSn2qyIAAoSkeMS3mblyx0/cenjs3lihtqsSOGmIBE5TmbGFc1rMC2lA10aV+Xf09bQ7cnZLNm0K9qliUSFgkTkBJ2SWIwnrm3Os32S2LXvEFeMnMM/PlrF/oNHol2ayEmVoyAxs545GRMpjMLbrIxJ3UDXEanMXa82K1J45PSI5N4cjokUSultVt747bkAXPfMfO59R21WpHAocqyFZnYxcAlQ3cweD1tUBlCbVJEM2pxekckDkxk+fQ3PzNrAx19s4+HujencqGq0SxOJmOyOSLYAacDPwMKwnwlAl8iWJlIwlUiI595LzuK9O9tSvmQC/V9ZyJ2vL2L7ngPZryxSAOXowlZmVtTdDwW3ywM13X1ppIvLK7qwlUTLoSNHGZO6gREz1lKiaDz/d1lDrmpRHTOLdmki2crrC1tNM7MyZlYBWAK8YGZDc1WhSCGQ3mblo7vaU79yIn8Yt0RtViTm5DRIyrr7j8CVwAvufg7QMXJlicSWepUTGXtrGx7q3ohFG3+gy3C1WZHYkdMgKWJm1YCrgYkRrEckZsXFGX3a1GHK4GRa1gm1Wbl69Kes26Y2K1Kw5TRIHgKmAOvdfYGZnQasjVxZIrGrRvmSvHhzS4Ze3ZT12/dyyYjZPPnxWg4dUZsVKZhydLK9oNPJdsmvtu85wIMfrODDpVtpULU0Q3o05ewaZaNdlgiQxyfbzayGmb1rZtvM7Dsze9vMauS+TJHCrVLpYjx1XQvG9D6HH/YdpPtTs3lEbVakgMnpW1svEPruyKlAdeCDYExE8kDnRlWZOrgD17SsyWi1WZECJqdBUsndX3D3w8HPi0ClCNYlUuiULVGUR65swuu/bQ2E2qzc87barEj+l9Mg2WFmN5hZfPBzA7AzkoWJFFbnnX4Kkwcm0z/5NMambaLT0JlMWfFttMsSyVJOg+QWQh/9/RbYCvQAbo5UUSKFXYmEeP4ctFmpUCqBW19ZyJ2vqc2K5E85DZKHgRvdvZK7VyYULA9GrCoRAaBJjXJ88Lt2/LHLmUxb9R0dh85k/MLNFIZPW0rBkdMgaeLuP6TfcffvgeaRKUlEwqnNiuR3OQ2SuKBZIwBBz61jtqAXkbyVWZuVF+d8yVG1WZEoy2mQ/BuYa2YPm9lDwFzgsciVJSKZydhm5cEPVtJz9Kes27Y32qVJIZajIHH3l4GrgO+A7cCV7v5KduuZWVczW21m68zsnkyWp5jZSjNbamYzzKx22LLJZrbLzCZmWOciM1tkZovNbLaZ1cvJPojEkvQ2K//umd5mZRZPfbJObVYkKiLWIsXM4oE1QCdgM7AAuNbdV4bNuQCY7+77zOx24Hx3vyZYdhFQErjV3S8LW2cN0N3dV5nZHUArd7/pWLWoRYrEsu17DvDAhOV8tOxbGlYrw2M9mtC4utqsSO7l9fVITkQrYJ27b3D3g8CbQPfwCe7+ibunnzGcB9QIWzYDyKwtqhO61C9AWUJXcRQptCqVLsbI689h1A0t2L73AN2fmsNjk7/g50NqsyInRyRPmFcHNoXd3wy0Psb8vsCkHGy3H/CRme0HfgTOzWySmfUH+gPUqlUrJ/WKFGhdG1ejzWmn8LcPVzLyP+uZvOJbHruqCUl1KkS7NIlxkTwiyexaopm+jxZ8Uz4JGJKD7Q4GLnH3GoT6fWV6pUZ3H+PuSe6eVKmSurlI4VC2ZFGG9GzKy7e04sCho/Qc/SkPvL+cvQcOR7s0iWGRDJLNQM2w+zXI5G0oM+sI3Ad0c/djfm3XzCoBTd19fjD0FnBe3pQrEjuSz6jE1MHJ3NimDi/P20iXYanMXLM92mVJjIpkkCwA6ptZXTNLAHoR6iD8CzNrDowmFCLbcrDNH4CyZnZGcL8TsCoPaxaJGaWKFeHBbo0Yf1sbiheN48bnP+P3Y5ewa9/BaJcmMSZiQeLuh4EBhK6suAoY6+4rzOwhM+sWTBsCJALjgo/z/hI0ZjYLGAdcZGabzaxLsM3fAm+b2RKgN/DHSO2DSCw4p3YFPryrPQMuqMf7i7+h49BUPlq2NdplSQzRFRJFCpEVW3bzp7eXsvybH+naqCoPdW9E5TLFo12W5FP54eO/IpLPNDq1LO/d0ZY/dW3Ax6u30XHoTMambVITSMkVBYlIIVMkPo7bzz+dyQPb06BqGe4ev1RNICVXFCQihdRplRJ5s/+5PKwmkJJLChKRQiwuzujdpg5TUzr80gTy6tGfsn67mkBKzilIRITq5Urw4s0t+VfPpqzdtpeLR8xi5H/WcVhNICUHFCQiAoCZ0eOcGkxLSebCMyvz2OTVXD5yDiu3/Bjt0iSfU5CIyH+pXLo4o3qfw8jrW/Dt7p/p9uRshk5dzYHDagIpmVOQiEimLjm7GtMGd+A3TU/l8Y/Xcdnjs/n86x+yX1EKHQWJiGSpfKkEhl3TjBduasneA4e56um5/P3Dlew/qKMT+ZWCRESydUGDykwdnEyvVrV4ZtaXXDwilXkbdka7LMknFCQikiOlixflH1eczRu/PRcHeo2Zx33vLmPPz4eiXZpEmYJERI5Lm9MrMnlgMv3a1eWNz76m87BUPvkiJ827JVYpSETkuJVIiOf+yxry9u3nkVisCDe/uIDBby3mh5/Uor4wUpCIyAlrXqs8E+9qx10X1uODJVvoNGwmk9SivtBRkIhIrhQrEk9K5zOZMKAdVcsW5/bXFnH7qwvZtufnaJcmJ4mCRETyRMNTy/DeHW25u+uZzPhiG52GpvLOos1qUV8IKEhEJM8UiY/jjvPr8dFd7alXOZGUsUu45cUFbNm1P9qlSQQpSEQkz9WrnMjYW9vwwG8aMm/D93Qelsrr87/W0UmMUpCISETExxk3t63LlEHJNKlRlj+/u4zrnpnP1zt1Aa1YoyARkYiqVbEkr/VrzT+uOJtl3+ymy/BUnpv9JUd0Aa2YoSARkYgzM65rXYtpKcm0Ob0iD09cSc9Rc1m3bU+0S5M8oCARkZOmWtkSPHdjEsOvacaGHT9xyYjZPPXJOg7pAloFmoJERE4qM+Py5tWZNrgDnRpWYciU1Vz+1BxWbNkd7dLkBClIRCQqKpUuxlPXt2DUDS347scDdH9yDv+aogtoFUQKEhGJqq6NqzE9JZluzU7lyU9CF9BapAtoFSgKEhGJunIlExh6dTNeuLklPwUX0Hp4oi6gVVAoSEQk37jgzMpMGZzM9a1r8dzsL+kyPJW563dEuyzJhoJERPKV0sWL8rfLQxfQMoPrnpnPve8s40ddQCvfUpCISL6UfgGt/smn8daCr+k8NJWPv/gu2mVJJhQkIpJvlUiI58+XnMU7d7SlbImi3PJiGoPe/JzvdQGtfEVBIiL5XrOa5fjgd+0YeFF9Ji7dSqehM5m4dIuaQOYTEQ0SM+tqZqvNbJ2Z3ZPJ8hQzW2lmS81shpnVDls22cx2mdnEDOuYmf3dzNaY2SozuyuS+yAi+UNCkTgGdzqDiXfA+0ogAAAQ1ElEQVS1o3r5Egx4/XNufWUh237UBbSiLWJBYmbxwFPAxUBD4Foza5hh2udAkrs3AcYDj4UtGwL0zmTTNwE1gQbufhbwZh6XLiL5WIOqZXjn9vO49+IGzFyznY5DZzI2bZOOTqIokkckrYB17r7B3Q8SesHvHj7B3T9x9/Se0vOAGmHLZgCZdXS7HXjI3Y8G87ZFongRyb+KxMdxa4fTmTSwPQ2qluHu8Uvp8/xnbPpeLeqjIZJBUh3YFHZ/czCWlb7ApBxs93TgGjNLM7NJZlY/s0lm1j+Yk7Z9+/YcFy0iBcdplRJ5s/+5PNy9EYs2/kCX4am8NPcrjqpF/UkVySCxTMYyfXbN7AYgidDbWdkpBvzs7knAM8DzmU1y9zHunuTuSZUqVcphySJS0MTFGb3b1GHK4GTOqV2eByas4Joxn7Jh+95ol1ZoRDJINhM6l5GuBrAl4yQz6wjcB3Rz9wM53O7bwe13gSa5rFNEYkCN8iV5+ZZWDOnRhNXf7qHriFk8/Z/1HFaL+oiLZJAsAOqbWV0zSwB6ARPCJ5hZc2A0oRDJ6bmO94ALg9sdgDV5VK+IFHBmRs+kmkz/fQcuPLMy/5z8BVeMnMvKLT9Gu7SYFrEgcffDwABgCrAKGOvuK8zsITPrFkwbAiQC48xssZn9EjRmNgsYB1xkZpvNrEuw6FHgKjNbBjwC9IvUPohIwVS5dHFG9T6Hp69vwdbdP9Ptydn8e6pa1EeKFYaPzCUlJXlaWlq0yxCRKNi17yAPTVzJO4u+oX7lRP7ZowktapWPdlkFgpktDM5HH5O+2S4iMS2zFvUPfbCSfQcPR7u0mKEgEZFC4YIzKzM1pQM3tK7N83O+pOvwWcxdpxb1eUFBIiKFRmKxIjx8eWPe6n8u8XHGdc/O5563l6pFfS4pSESk0Gl9WkUmDWzPrcmnMTZtE52GzmT6SrWoP1EKEhEplIoXjefeS87ivTvbUr5kAv1eTuN3b3zOzr05+TqbhFOQiEih1qRGOSYMaMfgjmcweflWOg1L5f3F36gJ5HFQkIhIoZdQJI6BHevz4V3tqVmhJAPfXMxvX07j291qUZ8TChIRkcAZVUrzzu3ncf+lZzF73Q46DZ3JG599raOTbChIRETCxMcZ/dqfxpRByTSuXpZ731nGdc/MZ+POn6JdWr6lIBERyUTtiqV4/bet+ccVZ7P8m910GZ7Ks7M2cEQt6v+HgkREJAtmxnWtazEtpQPt6p3C3z5cxZVPz2X1t5ldc6/wUpCIiGSjatniPNMniRG9mrHp+31c9sQshk9fw8HDalEPChIRkRwxM7o3q860wclccnY1hk9fS7cnZ7Nk065olxZ1ChIRkeNQMbEYI3o159k+Sfyw7yBXjJzDIx+t4udDhbdFvYJEROQEdGxYhWkpHbimZU1Gp26g6/BU5m3YGe2yokJBIiJygsoUL8ojVzbh9X6tOerQa8w8/vzuskLXBFJBIiKSS+fVO4Upg5Lp164ub372NZ2HpjJjVeFpAqkgERHJAyUS4rn/soa8fft5lClRhL4vpTHwzcLRBFJBIiKSh5rXKs/E37Vn4EX1+WhZ4WgCqSAREcljCUXiGNzpDCb+7tcmkP1eSmPr7v3RLi0iFCQiIhFyZtVfm0DOWb+DTkNTeW3+Ro7GWJsVBYmISASlN4GcOqgDTWuW5b53l3PtM/P4ckfsNIFUkIiInAS1Kpbk1b6teeyqJqzc+iNdh6cyauZ6Dh8p+G1WFCQiIieJmXF1y5pMT+lAhzMq8eikL7hi5FxWbvkx2qXlioJEROQkq1KmOKN7n8NT17Vg6+79dHtyNv+eupoDhwtmmxUFiYhIFJgZlzapxrTBHejW9FSe+Hgdlz4+m4Ubf4h2acdNQSIiEkXlSyUw9JpmvHhzS/YfPEKPUXP56wcr+OnA4WiXlmMKEhGRfOD8MyszZXAyvc+tzQtzvqLzsFRS12yPdlk5oiAREcknEosV4aHujRl3WxuKFY2jz/Of8fuxS9i172C0SzsmBYmISD7Tsk4FPrqrPXdecDrvLf6GjkNTmbRsa7TLypKCREQkHypeNJ4/dmnAhAFtqVq2GLe/tohbX0lj248/R7u0/xHRIDGzrma22szWmdk9mSxPMbOVZrbUzGaYWe2wZZPNbJeZTcxi20+Y2d5I1i8iEm2NTi3Le3e05Z6LG/Cf1dvpOHQmYxdsyldNICMWJGYWDzwFXAw0BK41s4YZpn0OJLl7E2A88FjYsiFA7yy2nQSUy/OiRUTyoSLxcdzW4XQmD0rmrGpluPvtpdzw3Hy+3rkv2qUBkT0iaQWsc/cN7n4QeBPoHj7B3T9x9/S/iXlAjbBlM4A9GTcaBNQQ4O5IFS4ikh/VPaUUb/z2XP5+RWOWbNpNl+GpPDtrA0ei3AQykkFSHdgUdn9zMJaVvsCkHGx3ADDB3Y955snM+ptZmpmlbd9eMD5CJyKSnbg44/rWtZmWksx5p1fkbx+u4sqn57L62//5vfvk1RTBbVsmY5nGppndACQROtLIeoNmpwI9gSeye3B3H+PuSe6eVKlSpRyUKyJScFQrW4Jnb0xiRK9mbPp+H5c9MYth09Zw8PDJbwIZySDZDNQMu18D2JJxkpl1BO4Durl7dtekbA7UA9aZ2VdASTNblzfliogULGZG92bVmZ7SgUvPrsaIGWu57IlZLPr65LZZiWSQLADqm1ldM0sAegETwieYWXNgNKEQ2ZbdBt39Q3ev6u513L0OsM/d60WgdhGRAqNCqQSG92rOCze1ZO/Ph7nq6ZPbZiViQeLuhwmdz5gCrALGuvsKM3vIzLoF04YAicA4M1tsZr8EjZnNAsYBF5nZZjPrEqlaRURiwQUNKjM1pcN/tVk5GedOLD99FjlSkpKSPC0tLdpliIicNAu++p4nPl7H09e3oFSxIie0DTNb6O5J2c07sa2LiEi+1rJOBV6+pdVJeSy1SBERkVxRkIiISK4oSEREJFcUJCIikisKEhERyRUFiYiI5IqCREREckVBIiIiuVIovtluZtuBjSe4+inAjjwsp6AojPtdGPcZCud+a59zpra7Z9s+vVAESW6YWVpOWgTEmsK434Vxn6Fw7rf2OW/prS0REckVBYmIiOSKgiR7Y6JdQJQUxv0ujPsMhXO/tc95SOdIREQkV3REIiIiuaIgERGRXFGQHIOZdTWz1Wa2zszuiXY9kWBmNc3sEzNbZWYrzGxgMF7BzKaZ2drgz/LRrjWvmVm8mX1uZhOD+3XNbH6wz2+ZWUK0a8xrZlbOzMab2RfBc94m1p9rMxsc/NtebmZvmFnxWHyuzex5M9tmZsvDxjJ9bi3k8eC1bamZtcjNYytIsmBm8cBTwMVAQ+BaM2sY3aoi4jDwe3c/CzgXuDPYz3uAGe5eH5gR3I81A4FVYff/CQwL9vkHoG9UqoqsEcBkd28ANCW0/zH7XJtZdeAuIMndGwPxQC9i87l+EeiaYSyr5/ZioH7w0x94OjcPrCDJWitgnbtvcPeDwJtA9yjXlOfcfau7Lwpu7yH0wlKd0L6+FEx7Cbg8OhVGhpnVAC4Fng3uG3AhMD6YEov7XAZIBp4DcPeD7r6LGH+uCV1SvISZFQFKAluJwefa3VOB7zMMZ/Xcdgde9pB5QDkzq3aij60gyVp1YFPY/c3BWMwyszpAc2A+UMXdt0IobIDK0assIoYDdwNHg/sVgV3ufji4H4vP92nAduCF4C29Z82sFDH8XLv7N8C/gK8JBchuYCGx/1yny+q5zdPXNwVJ1iyTsZj9rLSZJQJvA4Pc/cdo1xNJZnYZsM3dF4YPZzI11p7vIkAL4Gl3bw78RAy9jZWZ4JxAd6AucCpQitDbOhnF2nOdnTz9964gydpmoGbY/RrAlijVElFmVpRQiLzm7u8Ew9+lH+oGf26LVn0R0BboZmZfEXrL8kJCRyjlgrc/IDaf783AZnefH9wfTyhYYvm57gh86e7b3f0Q8A5wHrH/XKfL6rnN09c3BUnWFgD1g093JBA6QTchyjXlueDcwHPAKncfGrZoAnBjcPtG4P2TXVukuPu97l7D3esQel4/dvfrgU+AHsG0mNpnAHf/FthkZmcGQxcBK4nh55rQW1rnmlnJ4N96+j7H9HMdJqvndgLQJ/j01rnA7vS3wE6Evtl+DGZ2CaHfVOOB593971EuKc+ZWTtgFrCMX88X/JnQeZKxQC1C/xl7unvGE3kFnpmdD/zB3S8zs9MIHaFUAD4HbnD3A9GsL6+ZWTNCHzBIADYANxP6hTJmn2sz+ytwDaFPKH4O9CN0PiCmnmszewM4n1C7+O+AB4D3yOS5DUL1SUKf8toH3OzuaSf82AoSERHJDb21JSIiuaIgERGRXFGQiIhIrihIREQkVxQkIiKSKwoSKbDMbG7wZx0zuy6Pt/3nzB4rUszscjP7S4S2/efsZx33Ns82sxfzertSMOnjv1LghX8X5DjWiXf3I8dYvtfdE/OivhzWMxfo5u47crmd/9mvSO2LmU0HbnH3r/N621Kw6IhECiwz2xvcfBRob2aLg2tPxJvZEDNbEFxr4dZg/vkWuvbK64S+gImZvWdmC4PrVfQPxh4l1C12sZm9Fv5YwTeBhwTXtlhmZteEbfs/9uu1Pl4LvvSFmT1qZiuDWv6VyX6cARxIDxEze9HMRpnZLDNbE/QGS79+So72K2zbme3LDWb2WTA2OrhkAma218z+bmZLzGyemVUJxnsG+7vEzFLDNv8Boc4AUti5u370UyB/gL3Bn+cDE8PG+wP3B7eLAWmEmvadT6hRYd2wuRWCP0sAy4GK4dvO5LGuAqYR6nZQhdC3hasF295NqGdRHPAp0I7QN6dX8+vRf7lM9uNm4N9h918EJgfbqU+oL1Lx49mvzGoPbp9FKACKBvdHAn2C2w78Jrj9WNhjLQOqZ6yfUM+yD6L970A/0f9Jb1omEks6A03MLL2XUllCL8gHgc/c/cuwuXeZ2RXB7ZrBvJ3H2HY74A0PvX30nZnNBFoCPwbb3gxgZouBOsA84GfgWTP7EJiYyTarEWrvHm6sux8F1prZBqDBce5XVi4CzgEWBAdMJfi1kd/BsPoWAp2C23OAF81sLKGmh+m2EeqoK4WcgkRikQG/c/cp/zUYOpfyU4b7HYE27r7PzP5D6Df/7LadlfBeTUeAIu5+2MxaEXoB7wUMINRtONx+QqEQLuPJSyeH+5UNA15y93szWXbI3dMf9wjB64O732ZmrQldCGyxmTVz952E/q725/BxJYbpHInEgj1A6bD7U4DbLdQeHzM7w0IXcMqoLPBDECINCF1qON2h9PUzSAWuCc5XVCJ0xcHPsirMQtd5KevuHwGDgGaZTFsF1Msw1tPM4szsdEIXpFp9HPuVUfi+zAB6mFnlYBsVzKz2sVY2s9Pdfb67/wXYwa/tx88g9HagFHI6IpFYsBQ4bGZLCJ1fGEHobaVFwQnv7WR+KdXJwG1mtpTQC/W8sGVjgKVmtshDLebTvQu0AZYQOkq4292/DYIoM6WB982sOKGjgcGZzEkF/m1mFnZEsBqYSeg8zG3u/rOZPZvD/crov/bFzO4HpppZHHAIuBPYeIz1h5hZ/aD+GcG+A1wAfJiDx5cYp4//iuQDZjaC0Inr6cH3Mya6+/hsVosaMytGKOja+a+XrJVCSm9tieQP/wBKRruI41ALuEchIqAjEhERySUdkYiISK4oSEREJFcUJCIikisKEhERyRUFiYiI5Mr/A1yy7ABSb4u1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.9513309\n",
      "Test Accuracy: 0.9515554\n"
     ]
    }
   ],
   "source": [
    "parameters_DNN = model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 500, minibatch_size = 522878, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用訓練過後的模型，進行預測\n",
    "def predict_new(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    "    \n",
    "    params = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    x = tf.placeholder(\"float\", [14, 306313])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict_new(x, params)\n",
    "    p = tf.sigmoid(z3)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x: X})\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def forward_propagation_for_predict_new(X, parameters):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3'] \n",
    "                                                           # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KenChen\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     uid  label\n",
      "0  1000020_2705_20160519    0.0\n",
      "1  1000020_8192_20160513    0.0\n",
      "2  1000065_1455_20160527    0.0\n",
      "3  1000085_8067_20160513    0.0\n",
      "4  1000086_2418_20160613    0.0\n"
     ]
    }
   ],
   "source": [
    "test_dnn = testset[predictors].copy()\n",
    "test_dnn[mm_target] = mm.fit_transform(test_dnn[mm_target])\n",
    "test_dnn =  test_dnn.transpose().values\n",
    "\n",
    "dnn_pred = predict_new(test_dnn, parameters_DNN)\n",
    "dnn_pred = dnn_pred.transpose()\n",
    "\n",
    "output_06 = output.copy()\n",
    "output_06['pred_prob'] = dnn_pred\n",
    "out_06 = output_06.groupby(\"uid\", as_index=False).mean()\n",
    "out_06 = out_06[[\"uid\", \"pred_prob\"]]\n",
    "out_06.columns = [\"uid\", \"label\"]\n",
    "print(out_06.head())\n",
    "out_06.to_csv('DNN_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.040960e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.430904e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.264380e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.192093e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  3.040960e+05\n",
       "mean   1.430904e-11\n",
       "std    9.264380e-10\n",
       "min    0.000000e+00\n",
       "25%    0.000000e+00\n",
       "50%    0.000000e+00\n",
       "75%    0.000000e+00\n",
       "max    1.192093e-07"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_06.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
